{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "387af137",
      "metadata": {},
      "source": [
        "# Coding an LLM architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b032ac5",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "22196734",
      "metadata": {},
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "  \"vocab_size\": 50257, # vocab size \n",
        "  \"embed_dim\": 768, # embedding dimension\n",
        "  \"context_length\": 1024, # context length\n",
        "  \"drop_rate\": 0.1, # dropout rate\n",
        "  \"n_layers\": 12, # number of layers (how many transformer blocks we want to stack)\n",
        "  \"n_heads\": 12, # number of attention heads4\n",
        "  \"qkv_bias\": False # whether to use bias in the QKV layer\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f84abb8e",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DummyGPTModel(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"embed_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"embed_dim\"])\n",
        "    self.dropout = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    # Placeholder for the transformer blocks\n",
        "    self.trf_blocks = nn.Sequential(\n",
        "      *[DummyTransformerBlock(cfg[\"embed_dim\"]) for _ in range(cfg[\"n_layers\"])]\n",
        "    )\n",
        "\n",
        "    # Placeholder for layer norm\n",
        "    self.final_norm = DummyLayerNorm(cfg[\"embed_dim\"])\n",
        "    self.out_head = nn.Linear(\n",
        "      cfg[\"embed_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "    )\n",
        "\n",
        "  def forward(self, in_idx):\n",
        "    batch_size, seq_len = in_idx.shape\n",
        "    tok_embeds = self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.dropout(x)\n",
        "    x = self.trf_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "    return logits\n",
        "\n",
        "\n",
        "class DummyTransformerBlock(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    # just a placeholder for the transformer block\n",
        "    pass\n",
        "\n",
        "  def forward(self, x):\n",
        "    # does not do anything, just a placeholder\n",
        "    return x\n",
        "\n",
        "class DummyLayerNorm(nn.Module):\n",
        "  def __init__(self, normalized_shape, eps=1e-5):\n",
        "    super().__init__()\n",
        "    # just a placeholder for the layer norm\n",
        "    pass\n",
        "\n",
        "  def forward(self, x):\n",
        "    # does not do anything, just a placeholder\n",
        "    return x\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9d082352",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[15496,    11,   703,   389,   345,    30],\n",
            "        [   40,  1101,  3734,    11,  5176,     0]])\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "batch = []\n",
        "\n",
        "txt1 = \"Hello, how are you?\"\n",
        "txt2 = \"I'm fine, thanks!\"\n",
        "\n",
        "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
        "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
        "batch = torch.stack(batch, dim=0)\n",
        "print(batch)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "771e0a4e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 6])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5e1634e2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output shape: torch.Size([2, 6, 50257])\n",
            "Logits: tensor([[[ 0.1863, -0.5487,  0.4876,  ..., -0.0398,  0.4186, -0.1547],\n",
            "         [ 0.3518,  0.9714, -0.8348,  ...,  0.8093, -0.2861,  1.2434],\n",
            "         [-0.0855,  1.9188, -0.0133,  ...,  1.1934,  0.8300, -0.0104],\n",
            "         [ 0.0090, -0.6126,  0.6045,  ...,  1.6387,  0.7650, -0.7919],\n",
            "         [ 0.4482,  0.5461,  0.2741,  ..., -0.2531, -1.1501, -1.3639],\n",
            "         [ 0.0895,  0.2768, -0.4310,  ...,  1.2816,  0.5306,  0.3432]],\n",
            "\n",
            "        [[ 0.6431, -0.7578,  0.0666,  ...,  0.3780,  0.9720, -0.1389],\n",
            "         [ 1.3281,  0.1608, -0.6110,  ...,  0.3058, -0.3893,  1.5481],\n",
            "         [ 0.0215,  1.0764,  1.0452,  ...,  0.2514, -0.0103, -1.4550],\n",
            "         [ 1.0461,  1.4003, -0.0582,  ...,  2.1026, -0.2353, -0.6815],\n",
            "         [-1.1840,  0.1493,  1.0145,  ...,  0.5153, -0.6887, -0.5509],\n",
            "         [ 0.5185,  0.0710,  0.7378,  ...,  1.0410,  0.0434,  0.0287]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "model = DummyGPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "logits = model(batch)\n",
        "print(\"Output shape:\", logits.shape)\n",
        "print(\"Logits:\", logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dc20fd8",
      "metadata": {},
      "source": [
        "## Normalizing activations with layer normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9df22dfe",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
              "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085]])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "batch_example = torch.randn(2, 5)\n",
        "\n",
        "batch_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1fe3fbdf",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.7286, 0.6817, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1721, 0.0000, 0.0000, 0.0000, 0.8324, 0.1910]],\n",
              "       grad_fn=<ReluBackward0>)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_example = torch.randn(2, 5)\n",
        "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
        "out = layer(batch_example)\n",
        "out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "94ac81d5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2350],\n",
              "        [0.1992]], grad_fn=<MeanBackward1>)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# mean = out.mean(dim=1) # dim=1 means the mean of each row\n",
        "# or better use -1 as dim, which is the last dimension\n",
        "mean = out.mean(dim=-1, keepdim=True)\n",
        "mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "49d3a758",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.1328],\n",
              "        [0.1041]], grad_fn=<VarBackward0>)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "var = out.var(dim=-1, keepdim=True)\n",
        "var"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "18e9ebc9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.0000],\n",
              "        [1.0000]], grad_fn=<VarBackward0>)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.set_printoptions(sci_mode=False)\n",
        "\n",
        "normed = ((out - mean) / torch.sqrt(var))\n",
        "normed.var(dim=-1, keepdim=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c6573089",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.0000],\n",
              "        [1.0000]], grad_fn=<VarBackward0>)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "normed.var(dim=-1, keepdim=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3b06c232",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import norm_except_dim\n",
        "\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self, emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps = 1e-5 # 0.00001\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "  def forward(self, x):\n",
        "    mean = x.mean(dim=-1, keepdim=True)\n",
        "    var = x.var(dim=-1, keepdim=True, unbiased=False) \n",
        "    # unbiased=False means we use the population variance to mimic the gpt2 implementation\n",
        "    norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "    return self.scale * norm_x + self.shift\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "1ac64770",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 1.4835,  1.3425, -0.7065, -0.7065, -0.7065, -0.7065],\n",
              "        [-0.0920, -0.6763, -0.6763, -0.6763,  2.1489, -0.0280]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ln = LayerNorm(6)\n",
        "outputs_normed = ln(out)\n",
        "outputs_normed\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "59d9d271",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0000],\n",
              "        [-0.0000]], grad_fn=<MeanBackward1>)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs_normed.mean(dim=-1, keepdim=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ff962152",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.1999],\n",
              "        [1.1999]], grad_fn=<VarBackward0>)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs_normed.var(dim=-1, keepdim=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb690efe",
      "metadata": {},
      "source": [
        "## Implementing a feed forward network with GELU activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "bf547be9",
      "metadata": {},
      "outputs": [],
      "source": [
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # we are using the approximation of the GELU activation function to mimic the gpt2 implementation\n",
        "    return 0.5 * x * (1 + torch.tanh(\n",
        "      torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
        "      (x + 0.044715 * torch.pow(x, 3.0))\n",
        "    ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "682f4510",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.5587, 0.5128, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.0978, 0.0000, 0.0000, 0.0000, 0.6636, 0.1100]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gelu = GELU()\n",
        "gelu(out)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dab7a06",
      "metadata": {},
      "source": [
        "### Visualize the GELU function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c11a1200",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gelu, relu = GELU(), nn.ReLU()\n",
        "\n",
        "# sample data\n",
        "x = torch.linspace(-3, 3, 100)\n",
        "y_gelu = gelu(x)\n",
        "y_relu = relu(x)\n",
        "\n",
        "# plot the results\n",
        "plt.figure(figsize=(8, 3))\n",
        "\n",
        "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
        "  plt.subplot(1, 2, i)\n",
        "  plt.plot(x, y)\n",
        "  plt.title(f\"{label} activation function\")\n",
        "  plt.xlabel(\"x\")\n",
        "  plt.ylabel(f\"{label}(x)\")\n",
        "  plt.grid(True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "10a39a31",
      "metadata": {},
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "      nn.Linear(cfg[\"embed_dim\"], 4 * cfg[\"embed_dim\"]), # 4 is what gpt2 uses\n",
        "      GELU(),\n",
        "      nn.Linear(4 * cfg[\"embed_dim\"], cfg[\"embed_dim\"])\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1d7d5bd2",
      "metadata": {},
      "outputs": [],
      "source": [
        "ffn = FeedForward(GPT_CONFIG_124M)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "73d22e41",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 768])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.randn(2, 3, 768)\n",
        "ffn(x).shape\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5cbf5f23",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 0.0148, -0.0353, -0.0022,  ...,  0.0333, -0.0356,  0.0199],\n",
              "        [-0.0170, -0.0258,  0.0280,  ...,  0.0240,  0.0314,  0.0344],\n",
              "        [ 0.0082,  0.0230,  0.0001,  ..., -0.0335,  0.0171, -0.0037],\n",
              "        ...,\n",
              "        [ 0.0281,  0.0268, -0.0041,  ..., -0.0031, -0.0273, -0.0046],\n",
              "        [-0.0025, -0.0127, -0.0169,  ..., -0.0045, -0.0046, -0.0345],\n",
              "        [ 0.0264, -0.0037,  0.0053,  ..., -0.0051, -0.0041,  0.0070]],\n",
              "       requires_grad=True)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ffn.layers[0].weight"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6fcad3c",
      "metadata": {},
      "source": [
        "## Adding shortcut connections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2eefd809",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ExampleDeepNeuralNetwork(nn.Module):\n",
        "  def __init__(self, layer_sizes, use_shortcut):\n",
        "    super().__init__()\n",
        "    self.use_shortcut = use_shortcut\n",
        "    self.layers = nn.ModuleList([\n",
        "      nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
        "      nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
        "      nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
        "      nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
        "      nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU()),\n",
        "    ])\n",
        "    \n",
        "  def forward(self, x):\n",
        "    for layer in self.layers:\n",
        "     # computer the output of the current layer\n",
        "     layer_output = layer(x)\n",
        "     # check if shortcut can be applied\n",
        "     if self.use_shortcut and x.shape == layer_output.shape:\n",
        "      x = x + layer_output\n",
        "     else:\n",
        "      x = layer_output\n",
        "    return x\n",
        "\n",
        "def print_gradients(model, x):\n",
        "  # forward pass\n",
        "  output = model(x)\n",
        "  target = torch.tensor([[0.]]) # placeholder target for the loss function as we are not training\n",
        "\n",
        "  # compute loss\n",
        "  loss = nn.MSELoss() # just for simplicity, we use a simple loss function\n",
        "  loss = loss(output, target)\n",
        "\n",
        "  # backward pass to calculate gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # print the gradients\n",
        "  for name, param in model.named_parameters():\n",
        "    if 'weight' in name:\n",
        "      # print the mean absolute gradients of the weights\n",
        "      print(f\"{name} has a gradient mean of {param.grad.abs().mean().item()}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f8396351",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layers.0.0.weight has a gradient mean of 0.00020173587836325169\n",
            "layers.1.0.weight has a gradient mean of 0.0001201116101583466\n",
            "layers.2.0.weight has a gradient mean of 0.0007152041071094573\n",
            "layers.3.0.weight has a gradient mean of 0.0013988735154271126\n",
            "layers.4.0.weight has a gradient mean of 0.005049645435065031\n"
          ]
        }
      ],
      "source": [
        "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
        "sample_input = torch.tensor([[1., 0., -1.]])\n",
        "use_shortcut = False\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "model = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut)\n",
        "\n",
        "print_gradients(model, sample_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "09c924b7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layers.0.0.weight has a gradient mean of 0.22169791162014008\n",
            "layers.1.0.weight has a gradient mean of 0.20694106817245483\n",
            "layers.2.0.weight has a gradient mean of 0.32896995544433594\n",
            "layers.3.0.weight has a gradient mean of 0.2665732204914093\n",
            "layers.4.0.weight has a gradient mean of 1.3258540630340576\n"
          ]
        }
      ],
      "source": [
        "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
        "sample_input = torch.tensor([[1., 0., -1.]])\n",
        "use_shortcut = True\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "model = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut)\n",
        "\n",
        "print_gradients(model, sample_input)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2eb50ced",
      "metadata": {},
      "source": [
        "## Connecting attention and linear layers in a transformer block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcb52792",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import code from chapter-3.ipynb and chapter-2.ipynb that we need here\n",
        "import sys\n",
        "# Add the directory containing this notebook to Python path\n",
        "notebook_dir = '/Users/wolf/ai/LLMs-from-scratch/build_an_llm_from_scratch'\n",
        "if notebook_dir not in sys.path:\n",
        "    sys.path.insert(0, notebook_dir)\n",
        "    \n",
        "from previous_chapters_two_three import MultiHeadAttention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b9592093",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.attn = MultiHeadAttention(\n",
        "      d_in = cfg[\"embed_dim\"],\n",
        "      d_out = cfg[\"embed_dim\"],\n",
        "      context_length = cfg[\"context_length\"],\n",
        "      num_heads = cfg[\"n_heads\"],\n",
        "      dropout = cfg[\"drop_rate\"],\n",
        "      qkv_bias = cfg[\"qkv_bias\"]\n",
        "    )\n",
        "\n",
        "    self.ff = FeedForward(cfg)\n",
        "    self.norm1 = LayerNorm(cfg[\"embed_dim\"])\n",
        "    self.norm2 = LayerNorm(cfg[\"embed_dim\"])\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self, x):\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "    x = self.ff(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "\n",
        "    shortcut = x # keep the x from the previous layer for the shortcut connection\n",
        "    x = self.norm2(x)\n",
        "    x = self.attn(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut # add the shortcut connection\n",
        "\n",
        "    return x\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "c0fa96aa",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.1416,  0.2467,  0.2317,  ...,  0.1780,  0.1966,  1.3443],\n",
              "         [ 0.0929,  0.3889,  0.6629,  ...,  1.1015,  0.3640,  0.4361],\n",
              "         [ 0.2067,  0.5458,  0.1572,  ..., -0.2758,  0.6164,  0.4802],\n",
              "         [ 0.4659,  0.4988,  0.8070,  ..., -0.1181,  0.2424,  1.3027]],\n",
              "\n",
              "        [[ 0.9658,  1.2531,  1.2318,  ...,  0.5799,  0.0377,  0.4316],\n",
              "         [ 0.5739, -0.0013,  0.6739,  ...,  0.3818,  0.5303,  0.2684],\n",
              "         [ 0.9065,  0.4001,  0.2467,  ...,  0.1645,  0.8935,  1.2748],\n",
              "         [ 0.9911,  0.7147,  0.3522,  ...,  0.6840,  0.2418,  0.5326]]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "model = TransformerBlock(GPT_CONFIG_124M)\n",
        "\n",
        "x = torch.rand(2, 4, 768)\n",
        "\n",
        "output = model(x)\n",
        "output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "a84fb728",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 768])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "6d2b98c0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 768])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4eac2ac9",
      "metadata": {},
      "source": [
        "## Coding the GPT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "bb75ec3b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[6109, 3626, 6100,  345],\n",
            "        [6109, 1110, 6622,  257]])\n"
          ]
        }
      ],
      "source": [
        "# copied from above\n",
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "batch = []\n",
        "\n",
        "txt1 = \"Every effort moves you\"\n",
        "txt2 = \"Every day holds a\"\n",
        "\n",
        "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
        "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
        "batch = torch.stack(batch, dim=0)\n",
        "print(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "5fc75eb4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "ed361f9f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# based on the DummyGPTModel class from above\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"embed_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"embed_dim\"])\n",
        "    self.dropout = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    # Placeholder for the transformer blocks\n",
        "    self.trf_blocks = nn.Sequential(\n",
        "      *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "    )\n",
        "\n",
        "    # Placeholder for layer norm\n",
        "    self.final_norm = LayerNorm(cfg[\"embed_dim\"])\n",
        "    self.out_head = nn.Linear(\n",
        "      cfg[\"embed_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "    )\n",
        "\n",
        "  def forward(self, in_idx):\n",
        "    batch_size, seq_len = in_idx.shape\n",
        "    tok_embeds = self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.dropout(x)\n",
        "    x = self.trf_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "55602469",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0.7053,  0.3617,  0.0581,  ...,  0.5794,  0.4369, -0.5395],\n",
              "         [ 0.3149, -0.4990, -0.7606,  ...,  0.0588,  0.2850, -0.2483],\n",
              "         [ 1.0219,  0.0603,  0.0629,  ..., -0.0370, -0.3881, -0.1416],\n",
              "         [-0.5710,  0.1734, -0.4368,  ...,  0.8466,  0.2312, -0.2404]],\n",
              "\n",
              "        [[-0.3798,  0.2834, -0.1104,  ...,  0.1926,  0.3591, -0.8746],\n",
              "         [ 0.1633,  0.2323,  0.2081,  ...,  0.9451, -0.2375,  0.3755],\n",
              "         [ 1.0812,  0.8785, -0.1139,  ...,  0.8412,  0.3455, -0.1142],\n",
              "         [ 0.1560,  0.1270,  0.4120,  ...,  1.2442, -0.5060,  0.2523]]],\n",
              "       grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "\n",
        "\n",
        "output = model(batch)\n",
        "output "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "d05200dc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 50257])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "b5cf1e70",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch.numel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "05d98103",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "163009536"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "total_params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "a0c92f66",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters: 163,009,536\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total parameters: {total_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6241da7",
      "metadata": {},
      "source": [
        "We have more than 124 million parameters because we do not do weight sharing for input and output embedding. \n",
        "\n",
        "In the original GPT-2, the input embedding matrix (tok_emb) and the output projection matrix (out_head) share the same weights. This reduces parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "71a226c5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters of the original GPT-2 model: 124,412,160\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total parameters of the original GPT-2 model: {total_params - model.out_head.weight.numel():,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a0a5189",
      "metadata": {},
      "source": [
        "### Current implementation (no weight sharing)\n",
        "Looking at the GPTModel class:\n",
        "\n",
        "- `self.tok_emb = nn.Embedding(vocab_size, embed_dim)`  creates a matrix of size (50257, 768)\n",
        "- `self.out_head = nn.Linear(embed_dim, vocab_size, bias=False)`  creates a matrix of size (768, 50257)\n",
        "\n",
        "These are separate, so you have:\n",
        "\n",
        "- Embedding parameters: 50257  768 = 38,597,376\n",
        "- Output head parameters: 768  50257 = 38,597,376\n",
        "- Total for these two: 77,194,752 parameters\n",
        "\n",
        "### Original GPT-2 (with weight sharing)\n",
        "If the weights are shared (typically by tying `out_head.weight = tok_emb.weight.T`), you only store one set:\n",
        "- Shared parameters: 50257  768 = 38,597,376 parameters\n",
        "This saves about 38.6 million parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cb71c5c",
      "metadata": {},
      "source": [
        "## Generating Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "897fb9f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "  for _ in range(max_new_tokens):\n",
        "    idx_cond = idx[:, -context_size:] # truncating to the size the model supports (if it was longer)\n",
        "\n",
        "    with torch.no_grad(): # we are not training, so we do not need to compute gradients\n",
        "      logits = model(idx_cond)\n",
        "    logits = logits[:, -1, :] # only the last row of the logits (the new token)\n",
        "\n",
        "    probas = torch.softmax(logits, dim=-1) # computing the probabilities\n",
        "    idx_next = torch.argmax(probas, dim=-1, keepdim=True) # argmax looks up the index position (finding the index position with the highest probability)\n",
        "\n",
        "    idx = torch.cat((idx, idx_next), dim=1) # concatenating the new token to the context\n",
        "\n",
        "  return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f028b3b",
      "metadata": {},
      "source": [
        "idx (index) corresponds to token id "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "b676fa34",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoded: [15496, 11, 314, 716]\n",
            "encoded_tensor.shape: torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "start_context = \"Hello, I am\"\n",
        "\n",
        "encoded = tokenizer.encode(start_context)\n",
        "print(\"encoded:\", encoded)\n",
        "\n",
        "# model expects a batch dimension even if we only have one example\n",
        "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "da6c77ec",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[15496,    11,   314,   716]])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "a23a7a19",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[15496,    11,   314,   716, 45985,  7283, 46275, 31377, 10595,  8262]])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out = generate_text_simple(\n",
        "  model=model, \n",
        "  idx= encoded_tensor, \n",
        "  max_new_tokens=6, \n",
        "  context_size=GPT_CONFIG_124M[\"context_length\"] \n",
        ")\n",
        "out\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "aa23e660",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hello, I am pinnacle IT snowball maple wider chart'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(out[0].tolist()) # we have to convert the tensor to a list first because the tokenizer expects a list of tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43bf2d9f",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
