{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "387af137",
   "metadata": {},
   "source": [
    "# Coding an LLM architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b032ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /Users/wolf/ai/build_a_llm_from_scratch/.venv/bin/python\n",
      "Python path: /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python39.zip\n",
      "✓ Using virtual environment\n",
      "✓ torch version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "# Verify Python environment\n",
    "import sys\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python path: {sys.path[0]}\")\n",
    "\n",
    "# Check if we're in the virtual environment\n",
    "if '.venv' in sys.executable:\n",
    "    print(\"✓ Using virtual environment\")\n",
    "else:\n",
    "    print(\"⚠ WARNING: Not using virtual environment!\")\n",
    "    print(\"Please switch to 'Python (build-a-llm-from-scratch)' kernel\")\n",
    "\n",
    "# Try importing torch\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"✓ torch version: {torch.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"✗ torch not found - install with: !uv pip install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22196734",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "  \"vocab_size\": 50257, # vocab size \n",
    "  \"embed_dim\": 768, # embedding dimension\n",
    "  \"context_length\": 1024, # context length\n",
    "  \"drop_rate\": 0.1, # dropout rate\n",
    "  \"n_layers\": 12, # number of layers (how many transformer blocks we want to stack)\n",
    "  \"n_heads\": 12, # number of attention heads4\n",
    "  \"qkv_bias\": False # whether to use bias in the QKV layer\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f84abb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "  def __init__(self, cfg):\n",
    "    super().__init__()\n",
    "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"embed_dim\"])\n",
    "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"embed_dim\"])\n",
    "    self.dropout = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    # Placeholder for the transformer blocks\n",
    "    self.trf_blocks = nn.Sequential(\n",
    "      *[DummyTransformerBlock(cfg[\"embed_dim\"]) for _ in range(cfg[\"n_layers\"])]\n",
    "    )\n",
    "\n",
    "    # Placeholder for layer norm\n",
    "    self.final_norm = DummyLayerNorm(cfg[\"embed_dim\"])\n",
    "    self.out_head = nn.Linear(\n",
    "      cfg[\"embed_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "    )\n",
    "\n",
    "  def forward(self, in_idx):\n",
    "    batch_size, seq_len = in_idx.shape\n",
    "    tok_embeds = self.tok_emb(in_idx)\n",
    "    pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "    x = tok_embeds + pos_embeds\n",
    "    x = self.dropout(x)\n",
    "    x = self.trf_blocks(x)\n",
    "    x = self.final_norm(x)\n",
    "    logits = self.out_head(x)\n",
    "    return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "  def __init__(self, cfg):\n",
    "    super().__init__()\n",
    "    # just a placeholder for the transformer block\n",
    "    pass\n",
    "\n",
    "  def forward(self, x):\n",
    "    # does not do anything, just a placeholder\n",
    "    return x\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "  def __init__(self, normalized_shape, eps=1e-5):\n",
    "    super().__init__()\n",
    "    # just a placeholder for the layer norm\n",
    "    pass\n",
    "\n",
    "  def forward(self, x):\n",
    "    # does not do anything, just a placeholder\n",
    "    return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d082352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15496,    11,   703,   389,   345,    30],\n",
      "        [   40,  1101,  3734,    11,  5176,     0]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "\n",
    "txt1 = \"Hello, how are you?\"\n",
    "txt2 = \"I'm fine, thanks!\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "771e0a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e1634e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 6, 50257])\n",
      "Logits: tensor([[[ 0.1863, -0.5487,  0.4876,  ..., -0.0398,  0.4186, -0.1547],\n",
      "         [ 0.3518,  0.9714, -0.8348,  ...,  0.8093, -0.2861,  1.2434],\n",
      "         [-0.0855,  1.9188, -0.0133,  ...,  1.1934,  0.8300, -0.0104],\n",
      "         [ 0.0090, -0.6126,  0.6045,  ...,  1.6387,  0.7650, -0.7919],\n",
      "         [ 0.4482,  0.5461,  0.2741,  ..., -0.2531, -1.1501, -1.3639],\n",
      "         [ 0.0895,  0.2768, -0.4310,  ...,  1.2816,  0.5306,  0.3432]],\n",
      "\n",
      "        [[ 0.6431, -0.7578,  0.0666,  ...,  0.3780,  0.9720, -0.1389],\n",
      "         [ 1.3281,  0.1608, -0.6110,  ...,  0.3058, -0.3893,  1.5481],\n",
      "         [ 0.0215,  1.0764,  1.0452,  ...,  0.2514, -0.0103, -1.4550],\n",
      "         [ 1.0461,  1.4003, -0.0582,  ...,  2.1026, -0.2353, -0.6815],\n",
      "         [-1.1840,  0.1493,  1.0145,  ...,  0.5153, -0.6887, -0.5509],\n",
      "         [ 0.5185,  0.0710,  0.7378,  ...,  1.0410,  0.0434,  0.0287]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(\"Logits:\", logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc20fd8",
   "metadata": {},
   "source": [
    "## Normalizing activations with layer normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9df22dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
       "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "batch_example = torch.randn(2, 5)\n",
    "\n",
    "batch_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fe3fbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7286, 0.6817, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1721, 0.0000, 0.0000, 0.0000, 0.8324, 0.1910]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_example = torch.randn(2, 5)\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94ac81d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2350],\n",
       "        [0.1992]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean = out.mean(dim=1) # dim=1 means the mean of each row\n",
    "# or better use -1 as dim, which is the last dimension\n",
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49d3a758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1328],\n",
       "        [0.1041]], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = out.var(dim=-1, keepdim=True)\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18e9ebc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [1.0000]], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "normed = ((out - mean) / torch.sqrt(var))\n",
    "normed.var(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6573089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000],\n",
       "        [1.0000]], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed.var(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b06c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import norm_except_dim\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "  def __init__(self, emb_dim):\n",
    "    super().__init__()\n",
    "    self.eps = 1e-5 # 0.00001\n",
    "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "  def forward(self, x):\n",
    "    mean = x.mean(dim=-1, keepdim=True)\n",
    "    var = x.var(dim=-1, keepdim=True, unbiased=False) \n",
    "    # unbiased=False means we use the population variance to mimic the gpt2 implementation\n",
    "    norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "    return self.scale * norm_x + self.shift\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ac64770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4835,  1.3425, -0.7065, -0.7065, -0.7065, -0.7065],\n",
       "        [-0.0920, -0.6763, -0.6763, -0.6763,  2.1489, -0.0280]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln = LayerNorm(6)\n",
    "outputs_normed = ln(out)\n",
    "outputs_normed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59d9d271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0.0000],\n",
       "        [    -0.0000]], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_normed.mean(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff962152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1999],\n",
       "        [1.1999]], grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_normed.var(dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb690efe",
   "metadata": {},
   "source": [
    "## Implementing a feed forward network with GELU activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf547be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "  def forward(self, x):\n",
    "    # we are using the approximation of the GELU activation function to mimic the gpt2 implementation\n",
    "    return 0.5 * x * (1 + torch.tanh(\n",
    "      torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "      (x + 0.044715 * torch.pow(x, 3.0))\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "682f4510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5587, 0.5128, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0978, 0.0000, 0.0000, 0.0000, 0.6636, 0.1100]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gelu = GELU()\n",
    "gelu(out)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dab7a06",
   "metadata": {},
   "source": [
    "### Visualize the GELU function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c11a1200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAE8CAYAAADT6TmLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAABY0klEQVR4nO3dB3hUVdoH8H96Iwk1CRB6SQihIwgoReldXXfXT5eisBZAEdYCIkgRVFQsqGABVldWRKX3Ik1AOpJQA4SehJqEhNSZ73lPnGw6SZjJnXvn/3ueCzeTmeTck5kz75zyHiez2WwGEREREZEOOWtdACIiIiKi0mIwS0RERES6xWCWiIiIiHSLwSwRERER6RaDWSIiIiLSLQazRERERKRbDGaJiIiISLcYzBIRERGRbjGYJSIiIiLdYjBLuvbWW2/ByclJk9+9YMEC9bujo6PL/HdnZGTg1VdfRY0aNeDs7IyBAwfCHmlZR0R0d0OGDEHt2rUdrv2+ffs2hg0bhqCgIFWG0aNHwx5pWUd6wmDWjp09exYjR45Ew4YN4e3trY6wsDCMGDECf/zxR4FP+MKOmJgYdT8JKuTr999/v9DfKw1b3759C/zevn371OMlSCkrycnJ6vq2bNkCLUyfPh1Lly6FPZk3bx5mzpyJv/zlL/j3v/+Nl19+WdPy2GMdEVk+TFkOV1dXVK9eXQVwly5dKtXPlHZIftZPP/1U6H3k+9J2F0QeJ98vy/bs8uXLqg09dOgQyprW7XdRbZY8P55//nl89913+Mc//qFZWey1jvTEVesCUMFWrlyJv/3tb6rxffLJJ9GsWTPVA3f8+HH88ssv+OKLL1SwW6tWrVyPk9vLlSuX7+eVL18eeiUv9MmTJ6vzzp075/rehAkT8Prrr9u80ZOgMW/vpzR+f//73+Hh4YGytnnzZvWmPGvWLNgDe6wjIospU6agTp06SElJwe7du1UQs2PHDkRERMDT0xNGJ8GstKHSUdG8efNc3/vqq69gMpkM234X1Ybef//9mDRpErRmr3WkJwxm7dDp06dVACCB6qZNm1C1atVc33/33Xfx+eefq+A2LwkoKleuDEchwb4cWnBxcVGHFuLi4nTxAUXLOiKy6NWrF1q3bq3OZWhZ2khpR5cvX46//vWvcGRubm4O2X5LGyojnfZOyzrSE04zsEPvvfcekpKSMH/+/HyBrJAn9osvvqjmS9qrGzdu4F//+heaNGmieor9/PzUG8rhw4fz3Vd6S2SIRaZTSC+JXPOjjz6qgnqZFlGlShV1P/nkahkulPsXNJ8oPDwcXbp0yfc7pOdBejIl2LeQqRbt27dHpUqV4OXlhVatWuUbOpSfLX8LGcq3/G4ZoixqPqh80GjcuLHqjaxWrZqaFnLr1q1c95FP31LWo0ePqvLKFBIpn/zti2KZJvLrr78iMjIyu0wyPGUZ/sw7VGV5TM6pIXIN8neRoVbpTZVzqWf5m2VmZuaru48//lj9LeXvI/fr2bOnmnJij3VEdDcPPvig+l/amJxk5EvaiIoVK6rnugTAEvBq4dy5c3jhhRcQEhKi2idppx5//PEC55/La0emGknPq7ymgoODMWjQIFy7dk21B/fdd5+639ChQ7Nfo5b2IOec2fT0dHXtcr+8EhISVJ1IGyHS0tIwceJE1W76+/vDx8dH1au0TRYlbb8t6wGmTp2KevXqqWuRso0fPx6pqakFToeTHvY2bdqostWtWxfffvttkfVqaSdlZHPVqlXZZZKyFtZeFdS2lqR9suZ7XFnUkR4xmLXTKQb169dH27ZtSxVESgOW88gbJJSFM2fOqDmU8kL68MMP8corr+DIkSPo1KmTGvKykMBJ7iMvYmkUP/jgA7z00kuIj49XQ4DyIpepE+KRRx5Rc5vkkIagIDI1Y9u2bdlzhC3kxSy/V3q8LSRAa9GihRqClGFy+ZAgbxbSwFnI75LGQhppy+9+9tlnC71uaXgkMJMATa7lsccew9y5c9G9e3f1RpHTzZs3VVAoU0jkvqGhoXjttdewZs2aQn++1IeUQe4rb1iWMjVq1AglJXXfo0cP9SYpgb38baQcX375Za77PfPMM2pxhHx4kt4sGfKSRlGGa+2xjojuxhKsVKhQIfs2+XAow87Hjh1Tz3F5vkmAJh/2lixZUuZl3Lt3L3bu3KnarE8++QTPPfecGqmTIEqGpXMuZJLX3qeffqpeQ9KuyX0lML948aJqG6SNE//85z+zX6MdO3YssJdW2llpuyVYzUluk2DJ0oZKcPv111+r8ki7IK/rq1evqjbFMje3pO23pedcguSWLVuqaVTSLs2YMSNX220RFRWlPnx069ZN/b3k7ynBufwtCyP1IWWQ3nmZcmEpkyWgLInitE/Wfo8rizrSJTPZlfj4eLP8WQYOHJjvezdv3jRfvXo1+0hOTs7+3qRJk9TjCjpCQkKy73f27Fl128yZMwstQ61atcx9+vQp8Ht79+5Vj58/f36R15GSkmLOzMzMdZv8bg8PD/OUKVOyb5s3b576eR9++GG+n2EymdT/cq1yH7nGvCzXbXHixAn19aeffprrfi+88IK5XLlyueos57lIS0szh4eHmx966KFct/v4+JgHDx6c73dLHcjvkusScXFxZnd3d3P37t1zXfvs2bPV/eRaLTp16qRu+/bbb7NvS01NNQcFBZkfe+wx893I4xs3bpzrtl9//VX9TPk/J8vfPOffTK5Hbsv5txAtWrQwt2rVKvvrzZs3q/u9+OKLhf597LWOiCzPv40bN6p25MKFC+affvrJXKVKFdUWydcWDz/8sLlJkyaq7cr5HG/fvr25QYMG+V5nixcvLvT3yvdHjBhR4PfkcQW9TvPK2z6JXbt25XtNTJw4Ud32yy+/FPoaLardltettPkW69atU/ddsWJFrvv17t3bXLdu3eyvMzIy1Osx73tUYGCg+emnn86+rSTt96FDh9TXw4YNy3W/f/3rX+p2aY8spMxy27Zt27Jvk/ZF/q5jx441301B73N526ui2tbitk/Wfo8ryzrSE/bM2hn5tCsKWsQln4DlU5zl+Oyzz/Ld5+eff8aGDRtyHTJdoaxJT51lTq98Mr1+/bq6JhkyO3DgQK7yyifkUaNG5fsZpUlHIsM48ml70aJF2bfJ75fpA/369VPDdRY5z+UTtnxSlh6OnOUriY0bN6reDOnFzDmfefjw4WqaRc4eXyH18dRTT2V/7e7uroaCpFe7rEgPTk5y/Tl/v/x95O9Q0CKJ0vx99FhHpH9du3ZVbaaMLkgvlfS4yvQBGd2wjGjJgiCZP5uYmJg9qiXtlvQ0njp1qtTZD0orZ/skIxZSFhmxk7nyedtQ6RmUXj1rvEYfeugh1SbnbEOlfZT3Ehn5spC58PJ6tExFkjqU4W+ZmlHaNnT16tXq/zFjxuS6fezYser/vO2DzHm1TBkR8jeW95iyah+K0z5Z+z1Ob3VUVjir2M74+vpmDx3lJUOx0tDGxsbmegHlJENHZbEA7G4vQss8S5kbKXOTcs7DlGFtC5kzJC8sa05wlwZX5g/Jm4/MYZJ5TjLZP2dDbJnOMW3aNDUklnOuUWlz+skcNyHXk5M0cDJPyfJ9C3kjzfu7ZAgob9o1W7HMf837++WNK+ffR6YDyDw6a9BbHZExyAd/+aArH1glrZ1MRcqZYUOGYqVD9c0331RHQaQNkfbEWu7Wzty5c0cNHUtnhLRlWR2+WeQ6cr5GZaqOtUhbLD9v4cKFql2UepIMOhJQ521DZZ68DF3LlIacU4Qkc0RpyOtfPuRK0J6T5IKVID5v+1CzZs18PyNvG2ZLxWmfrP0ep7c6KisMZu2MTKSXyeEylyYvyxxaWyeglyBHGtKCWOZq3S2djcxBlTeFp59+Wk1Ul2BIXoDSI2fLNDBCGtxx48Zh8eLF6vf9+OOPql5lbpPF9u3b0b9/fxX8S8AtdS7zxeSNQxrxslDYKv+cb1rWeHPMu6Drbr/fnli7jsgxSW+ZJZuBzIF94IEH8H//9384ceKE6l2ztEmyuEl6YguSN3goigSA99qGSk+etEfShrVr1061YfIal3mRtm5D5XdI54nM/ZT6kjZU5oNKD7DFf/7zHzX3Ur4vayICAgLU61UC8LwL60qquB0K9tqGlkX7pFUd2SsGs3aoT58+amL9nj17VCNc1iQlmKzQLIg0/pb7FEWG9WWF5zfffJPrdlmMlrPnWFZj/v777+pTfWEpYkraUyq9AlJvMkwmiculV0Ea3Jw9MTL0I28m69aty3V7QVMyivv7LXUidSS9jBYyrC690zLUaUuWxSx5F/zl/aReEvL3kTqSIcSiemf1UkdEloBL2qfZs2erxV6W56K0QdZ4Dsrz3NJW3ksbOnjwYNXzmXNVfN7Xt7xGC+r8uJc2VD7kywd8aUMl8JcpGG+88Ua+8km9Sfua8+fnnZJUkt8tdSKBukzryLmoVUYj5brvVmf22oZa8z1O6zqyV5wza4dkm1JJ8yG9mvIELetPVL1791arYPPu6CRDThJkyydwWUV5tzeMvOWUntK8885kOEvmpsmbSl6Wx0tdiJJkZZDeWVltL0OK8vPzDo9J+aQByfmJW3q8C9rFSubXFed3y5ugDJfLyuOc1y4BvQwLyocUW5JGTK5LhlBzkp7n0pK/j1yLJaF3TjmvUS91RGRZfyAfeD/66CMVIEqbJrdJb+SVK1fy3V9W6Ze0DZX2Z//+/blul9fI999/r+b1y7BwSdtQyViQt5dQXqOS8rCgjAuWx8vr0/L7i0NG0WRu8YoVK9TKepkLW1AbmvN3CAnadu3alet+JWm/pd6E/F1ykow4wtbtgwSeImcbKvWdN8NLSVj7PU7rOrJX7Jm1Qw0aNFBD3U888YSaa2PZAUye+NJ7Jd+TxsayeCHvp+WCFo9JWo7AwMDsryXFizTieUkPpqRvkSBQ0lRJQC3pq2TxgXxKlx4AyVFnmfhfGElFIulgJF+h5HKVtFzSiOfsjROSC1F+nkxml55omaguOUtloZDkWBwwYIBaCCGT2OX3y7w36SGU/H5yFEYWcsiQoRxy/7y9LfKClxe/TD2Q4UaZDyfz6mQoMe98TEmnIuWR+8v8Uen5LShtmsw/lekNEvjJz5VpDNILI8Gk5HksbJ6ztcgwpPzN5A1PAnVpmGVesFxbaUnvleziJcGn9ATIdUmvgEzTkO9ZtuzUSx0RWcjQuLxeJLeoLISU17/0Qko+ZVmQKG2VdCZIcCYf7vPmyJbRHZkrmpf0pkpvr3x4lx5OSVMnQ/SSGlB+lwTLxVmUK22oBJLyupb2T8ohr7Gcaw4s1yHtvqW9lteijKTIArc5c+ao9w5pC2Q+pXwt6zIkuJXXZ1FzWyV4lbZEelqlTvKm/5PySa+sLDyT9lTem+TnS1lzrvkoSfstZZX6k+BRAjtJOSXvCzI3V96bCsohbk2S+1rSs0kbZRmN+uGHH1QwX1rWfo/Tuo7sltbpFKhwUVFR5ueff95cv359s6enp9nLy8scGhpqfu6551R6jpyKSs2VM6WIJU1TYcd3332XnWLl5ZdfNtepU8fs5uZm9vPzM3fp0sW8Zs2aYpVd0ttI6o+qVauqcnfo0EGllZF0JnLkTUHzxhtvZP8uSW3yl7/8xXz69Ons++zcuVOljJK0TjlTmORNW5KT/M6CUphYfPPNNyrljqQpkXqVtCwF/bzjx4+bO3bsqK5DvmdJQVVYGhdJMyU/T65F0tTI31Dq826ptQpKk1OYwh4vKV4kLYy3t7e5QoUK5meffdYcERFRYGouSaeVV0HXLyl4JJWbXJPUv6Q16tWrl3n//v12XUdEluefpKbKS1LD1atXTx3yHBfS5gwaNEi1QfLcrF69urlv374qnVfeNE2FHdu3b1f3u3jxomp75Ge4urqaK1asqH7W7t27i1V2eT0MHTrUXLlyZZVWsEePHup1Js/9vGnwrl+/bh45cqT6XfIaDQ4OVve5du1a9n2WLVtmDgsLU2XJ2R4U9nqStFE1atRQ9502bVqB358+fbp6rLShktZv5cqVBf68krTf6enp5smTJ2e/H0gZxo0blytlWlEpJAt6jylIYY+X50DXrl3VNUnbNH78ePOGDRsKTM1V3PbJ2u9xZVVHeuIk/2gdUBMRERERlQbnzBIRERGRbjGYJSIiIiLdYjBLRERERLrFYJaIiIiIdIvBLBERERHpFoNZIiIiItIth9s0QRK+S/JqSRxd0i3+iIiKQzIeJiYmqg0kZIMTo2E7SkT21I46XDArDXCNGjW0LgYROYALFy4UuFOf3rEdJSJ7akcdLpiVngRL5fj5+cFo0tPTsX79enTv3h1ubm5aF8cQWKe2YeR6TUhIUMGepb0xGrajVFKsU9swcr0mlKAddbhg1jIkJg2wURthb29vdW1Ge2JrhXVqG45Qr0Ydgmc7SiXFOrUNR6hXp2K0o8abzEVEREREDoPBLBERERHpFoNZIiIiItItTYPZL774Ak2bNs2ed9WuXTusWbOmyMcsXrwYoaGh8PT0RJMmTbB69eoyKy8Rkb1hO0pEjk7TYFZSLbzzzjvYv38/9u3bh4ceeggDBgxAZGRkgfffuXMnnnjiCTzzzDM4ePAgBg4cqI6IiIgyLzsRkT1gO0pEjk7TYLZfv37o3bs3GjRogIYNG+Ltt99GuXLlsHv37gLv//HHH6Nnz5545ZVX0KhRI0ydOhUtW7bE7Nmzy7zsROQY0jJMSEnPhL1iO0pEetgA4XZqhs1+vt2k5srMzFRDX0lJSWqYrCC7du3CmDFjct3Wo0cPLF26tNCfm5qaqo6cecss6SzkMBrLNRnx2rTCOnXsep3962msOHwF0x9pjNa1KhTrMVpdE9tRx3pu6gnr1LHrdf3RWLy5/CjG9wrFgGZVi/WYklyT5sHskSNHVKObkpKiehOWLFmCsLCwAu8bExODwMDAXLfJ13J7YWbMmIHJkyfnu12SDEtuNqPasGGD1kUwHNap49VrTDLw2R8uyDQ7Ye3W3YirbC7W45KTk1GW2I463nNTr1injlevqZnA9EMuuJXmhPW7DsPt0kGrt6OaB7MhISE4dOgQ4uPj8dNPP2Hw4MHYunVroQ1xSY0bNy5XL4RlRwnZLcOoyb7lSd2tWzfDJlAua6xTx6xXk8mMJ+ftRab5Fjo1rIw3nmpR7E0QLD2XZYXtqGM9N/WIdeq49freupO4lRaN4PKeeP/pDvByd7F6O6p5MOvu7o769eur81atWmHv3r1qTtfcuXPz3TcoKAixsbG5bpOv5fbCeHh4qCMv+aPb6x/eGox+fVpgnTpWvS78/Tz2nbsFb3cXvP1IE9VWFVdZXw/bUdsw+vVpgXXqWPV6MjYR83eeU+eTB4TDz8ez2I8tyfXYXZ5Zk8mUa25WTjKMtmnTply3ySeSwuaGERGVRlxCCmasOabOx3YPQXAFfQ2lsx0lIntY9DVhaQQyTGZ0CwvEw41yT2+yJk17ZmXoqlevXqhZsyYSExOxcOFCbNmyBevWrVPfHzRoEKpXr67ma4mXXnoJnTp1wgcffIA+ffrghx9+UKlovvzySy0vg4gM5q0VkUhMyUDTYH8MaV8b9oztKBHZo18OXMKeszfg6eaMSf2sM+XJLoPZuLg41dBeuXIF/v7+KvG3NMAy90OcP38ezs7/6zxu3769aqgnTJiA8ePHq1Q0sgI3PDxcw6sgIiPZcDQWq4/EwMXZCe882lT9b8/YjhKRvYlPTsf01VmjW6MeamDz0S1Ng9lvvvmmyO9L70Jejz/+uDqIiKwtMSUdby7N2jxg+IN1EVbN/hc3sR0lInszc/1xXE9KQ70qPqottTW7mzNLRKSV99edQExCCmpV8sborg20Lg4Rke4cvnAL3/9+Xp1PHRgOd1fbh5oMZomIABw4fxPf7s5adfv2wCbwdCte+hgiIsqSacpa9GU2A4+0qI729SqjLDCYJSKHl55pwrifj6gG+LGWwXigQdk0wERERrLw93M4cikevp6uGNc7tMx+L4NZInJ4X247gxOxiajo4443+jTSujhERLpzNTEV7607oc5f6RGCAN/i55S9VwxmicihRV9LwsebTqnzN/s2UgEtERGVjGQvkJSGTar748m2tVCWGMwSkUMn9R6/5AjSMkx4sEFlDGxeXesiERHpzq7T17Hk4CXIjt/TBoaXeUpDBrNE5LB+PnAJO09fh4ers2qAnaQlJiKiYpPOgDeXZaU0fLJtTTSrUR5ljcEsETmkG0lpeHvVUXU+umtD1Krko3WRiIh055sdZxEVdxuVfNzxSveyW/SVE4NZInJI01Ydxc3kdIQG+WLYg3W0Lg4Rke5cvJmMT/5cczC+dyP4e7tpUg4Gs0TkcH6Luqb2DZdZBTMebQI3FzaFREQlNWXFUdxJz0SbOhXxaEvt1hywBScih5KSnqkWfYlB99dCi5oVtC4SEZHubDoWi/VHY+Hq7KT5mgMGs0TkUD7dfArnricjyM8T/+oRonVxiIh0505aJiYtj1TnzzxYBw0DfTUtD4NZInIYJ2ISMXfrGXX+Vv/G8PXUZn4XEZGeffZrFC7evINq/p548aEGWheHwSwROQaTyYxxv/yBDJMZ3cIC0TM8SOsiERHpzumrtzF322l1PrFfY/h4uGpdJAazROQYFu45jwPnb8HH3QWT+zfWujhERLrcaGbisgikZ5rRJaQKejQOhD1gMEtEhheXkIJ31x5X5zJPtlp5L62LRESkOyv+uILforI2mpnc3342mmEwS0SGN3nlUbVneNNgfwxqV1vr4hAR6U5CSjqmrczaaGZkl/qoWckb9oLBLBEZ2q8n4rDqjytqr/DpjzQp8z3DiYiMYNaGk4hLTEWdyj74Z6e6sCcMZonIsJLTMjBhSdae4UPb10Z4dX+ti0REpDsRl+Lx753R6nzKgMbwcHWBPWEwS0SG9fGmU7h06w6ql/fCy90aal0cIiJdZoKZsDQCJjPQt2lVPNigCuwNg1kiMqRjVxLw9faz2T0J9pA+hohIbxbtu4BDF7IywUzoEwZ7xGCWiAzZkyBb1maazOgVHoSHG9lH+hgiIj25kZSGd9ZkZYIZ0z0EQf6esEeaBrMzZszAfffdB19fXwQEBGDgwIE4ceJEkY9ZsGCBSgWR8/D0tM/KJSLtcsoePH8L5TxcMakfc8oSEZXGO2uOIf5OOkKDfDG4XS3YK02D2a1bt2LEiBHYvXs3NmzYgPT0dHTv3h1JSUlFPs7Pzw9XrlzJPs6dO1dmZSYi+xaXmCOnbPeGdtuTQERkz/ZF38CP+y6q87cfCYeri/0O5mtasrVr12LIkCFo3LgxmjVrpnpdz58/j/379xf5OOmNDQoKyj4CAzmESERZpq48lp1T9h8OkFOWI1xEZG3pmSa88WcmmL+2DkarWhVhz+xqRUR8fLz6v2LFoivt9u3bqFWrFkwmE1q2bInp06ergLggqamp6rBISEhQ/0svsBxGY7kmI16bVlin+qnX7VHXsOLwZUgq2Sn9GsGUmQFTJspcWT5XLCNcEtBmZGRg/PjxaoTr6NGj8PHxKXKEK2fQay87+RCR9v69MxonYhNR3tsNr/dqBHtnN8GsBKajR49Ghw4dEB4eXuj9QkJCMG/ePDRt2lQFv++//z7at2+PyMhIBAcHF9hrMXny5Hy3r1+/Ht7e9rN7hbXJtA2yLtapfddrWibw7mHJfeiEBwNNOHdoB84dgiaSk5PLdIQrb6+r9NDKCFfHjh3vOsJFRJTTlfg7aoME8XrPUFT0cYe9s5tgVnoWIiIisGPHjiLv165dO3VYSCDbqFEjzJ07F1OnTs13/3HjxmHMmDG5emZr1Kihei6kZ8JopEdIgoNu3brBzc1N6+IYAutUH/U6a2MUrqWeQaCfBz4a1kEt/tKKZQRICxzhunccjbE+1ql+6nXK8kgkpWWiRQ1/PNIsSLO/WUl+r10EsyNHjsTKlSuxbdu2AntXiyJvgi1atEBUVFSB3/fw8FBHQY8zcmBi9OvTAuvUfus1Ki4RX+3Iyik7uX9jVCjnBS1p9TzhCJd1cTTG+lin9l2vx245Yc0xFzjBjG4VrmPt2jXQSklGuDQNZs1mM0aNGoUlS5Zgy5YtqFOnTol/RmZmJo4cOYLevXvbpIxEZN+kHZGFCumZZjwUGoAejR136JwjXNbB0RjrY53af72mpmfiw9m7JIxUabiG9w6FlkoywuWqdcO7cOFCLFu2TK3EjYmJUbf7+/vDyyurZ2XQoEGoXr266hkQU6ZMwf3334/69evj1q1bmDlzpkrNNWzYMC0vhYg08suBS/j97A14ujmrXllHXcjEES7rM/r1aYF1ar/1+tnWszh3I1lN1RrbI1Tzv1NJfr+mqbm++OILNcTVuXNnVK1aNftYtGhR9n0kVZfkkrW4efMmhg8frnoRpDdWIvedO3ciLMw+t1gjItu5lZyGt1cfU+cvPdwQNSoad8i7qJ5pCWRlhGvz5s33NMIl7S8ROZ7oa0n4fMtpdf5m3zD4eurrA4fm0wzuRqYf5DRr1ix1EBHJ5giy3WLDwHIY9mDJgzgj4AgXEd1rLDZxeSTSMkx4sEFl9Gmivw+1drEAjIiopPafu4H/7rmgzqcNbAI3O96dxtYjXEJGuHKaP3++2pTGMsLl7Oycb4RLAt8KFSqgVatWHOEiclBrI2Kw7eRVuLvod6oWg1ki0v3uNG3q2PfuNLbEES4iKq3bqRmYvOKoOn+uU13UrVIOeuSYXRlEpGsLfovG8Rj97E5DRGSPPtl0CjEJKahR0QsvdKkPvWIwS0S6cvnWHczamLU7zfhejXSxOw0Rkb05EZOIb/7Mzz2lfzg83WQHRX1iMEtEujJlxVEkp2Wida0K+EurkqWgIiIiqOlJE5YeQabJjO5hgegSGgA9YzBLRLrx6/E4rI2MgYuzE6Y9Eg5nZ/0tVCAi0trPBy5hb/RNeLu7YFL/grex1hMGs0SkCynpmZi4PGvR19MdaiM0yHg7TxERlUV+7hl/5uce3bUBqpfXdvtva2AwS0S68PmvUbhw4w6C/DwxumtDrYtDRKRL7607get/5uce2sEY+bkZzBKR3Ttz9TbmbD2jzif1C4OPB7MKEhGV1MHzN/HfPecNl5/bGFdBRIZeqDBJdqfJNKFTwyroGR6kdZGIiHQn0ySLviIgqakfa2ms/NwMZonIrq06cgXbT12Du6szpgzQ5+40RERa+8/uc4i8nAA/T1eM6x0KI2EwS0R2vTvN1JVZu9O80LkealXy0bpIRES6E5eYgvfXnVDnr/YMReVyHjASBrNEZLc+2nASsQmpqFXJG891qqd1cYiIdOntVceQmJqBZsH+eKJNTRgNg1kiskvHYxIwf2e0On+rf2Nd705DRKSVnVHXsOzQZUhabln0JXm6jYbBLBHZ5aKviUsj1YKFHo0D0SVE37vTEBFpIS3DhAnLsvJz/+P+WmgS7A8jYjBLRHZnycFL2BN9A15uLpjYT/+70xARaeGr7Wdw5mqSmiM7pnsIjIrBLBHZlfg76Zj+5+40ox6ub4jdaYiIytqFG8n4dPMpdf5Gn1D4e7nBqBjMEpFdmbXhJK7dTkPdKj4Y9kBdrYtDRKRLk1dEIiXdhPvrVsTA5tVhZAxmichuRF6Ox7e7shZ9TekfrnLLEhFRyWw4GouNx+Lg6uyEaQPDDZ+fm+8URGQXTCYzJi2LhMkM9GlSFQ80qKx1kYiIdCc5LQNvLY9U58M71kX9AF8YHYNZIrILvxy8hH3nbsLb3QUT+jbSujhERLr06eYoXLp1R603GPVQfTgCBrNEZBeLvmb8uejrxYcboKo/F30REZXUqdhEfLXtjDqf1C8M3u6ucASaBrMzZszAfffdB19fXwQEBGDgwIE4cSJru7WiLF68GKGhofD09ESTJk2wevXqMikvEdlu0df1pDTUq+KDpzvU0bo4RES6zM/95rIIZJjM6NooAN0bB8FRaBrMbt26FSNGjMDu3buxYcMGpKeno3v37khKSir0MTt37sQTTzyBZ555BgcPHlQBsBwREVlJgYlIX45dSfzfoq8BXPRFRFQayw5dxu4zN+Dp5oxJDpafW9P+57Vr1+b6esGCBaqHdv/+/ejYsWOBj/n444/Rs2dPvPLKK+rrqVOnqkB49uzZmDNnTpmUm4isw2wGpqw6lr3oq0N9LvoiIiqphDvpmLbqz/zcDzVAjYrecCR2NZkiPj5e/V+xYsVC77Nr1y6MGTMm1209evTA0qVLC7x/amqqOiwSEhLU/9ILLIfRWK7JiNemFdapbUh97rvmhH3nbsHLzRmv9WhgmDo2ynUQkT58tCkK126nZuXnftDxpmrZTTBrMpkwevRodOjQAeHh4YXeLyYmBoGBgbluk6/l9sLm5U6ePDnf7evXr4e3t3E/uUhvNVkX69S6UjKAZedc1PnDVdNx8LfNOAhjSE5OLrPfJW3cL7/8guPHj8PLywvt27fHu+++i5CQkLuuPXjzzTcRHR2NBg0aqMf07t27zMpNRNZx4TbwfcQFdT51QDg8XLPaVUdiN8GszJ2Vea87duyw6s8dN25crp5c6ZmtUaOGmpvr5+cHo5EeIQm6unXrBjc3425dV5ZYp7YhQ2KJ6RdQq6IX3hnaAR4GmitrGQEqy7UHspg2IyMD48ePV+3b0aNH4ePjU+TaAwmE+/bti4ULF6q1BwcOHCiyM4GI7EumyYwfz7ioqVr9m1Vz2KladhHMjhw5EitXrsS2bdsQHBxc5H2DgoIQGxub6zb5Wm4viIeHhzrykqDEyIGJ0a9PC6xT6zkZm4j/7Lmozif2bYRyXvlfo3pWls8Trj0gclw/7r+I80lOKOfhigl9HDc/t6vWaSRGjRqFJUuWYMuWLahT5+7zPNq1a4dNmzapKQkW0gjL7URk/+R1L7vTSI9CkwomdOROX1bFtQf3jvPkrY91an3Xb6fi/fWn1PmoznVQwcvFUPVbkmvRNJiVoTEZ3lq2bJnKNWuZ9+rv76/mfolBgwahevXqajhMvPTSS+jUqRM++OAD9OnTBz/88AP27duHL7/8UstLIaJiWhMRg52nr6sUXI/UztC6OIbCtQfWxXny1sc6tZ7vo5yRkOKMYB8zqsQfw+o/N56BA6490DSY/eKLL9T/nTt3znX7/PnzMWTIEHV+/vx5ODv/by6dLG6QAHjChAlqbpgsXJDeBM7zItLHnuHTVh5V588+WBuVUk5qXSRD4doD6+A8eetjnVrX3uib2LNrL5wAPF4nEz27G69eS7L2QPNpBncj0w/yevzxx9VBRPryxZbTuByfovYMH/5AHfy6kcGstXDtgfUZ/fq0wDq9d+mZJkxeeVyd/7V1ddR2O2fIei3J9Rhn+TAR2bXz15Mx9889w9/s2whe7o6XPsZWnQISyMrag82bN5do7UFOXHtApA/zfzuLE7GJqOjjjrHdGmhdHLtgF9kMiMj4pqw8irQMEx6oXxk9GgepNFJ077j2gMhxXL51Bx9tzFr09XqvUFTwdte6SHaBPbNEZHNbT17FxmOxcHV2wlv9w+DkJDO9yFprDySDgaw9qFq1avaxaNGi7PvI2oMrV67kW3sgwWuzZs3w008/ce0BkQ5MWXEUyWmZaF2rAv7SsujpRI6EPbNEZFPSGzt5RaQ6H9y+NuoH+GpdJEPh2gMix/Dr8TisjYyBi7MTpj0SDmdnJ2Rmal0q+8CeWSKyqX/vjMaZq0moXM4dL3Xl/C4iopJKSc/EpOVZnQJD29dGaJDxsojcCwazRGQzcYkp+HhT1vyuV3uEws/TWKttiYjKwudbTuP8jWQE+XlidLeGWhfH7jCYJSKbmbn2BG6nZqBpsD/+0orzu4iISurstSTM2XJanU/sF6a2rqXcGMwSkU0cunALi/dfVOdv9W+s5ncREVHJ5sRPXBaBtEwTOjasgl7hBeeCdnSlCu/Pnj2L7du349y5c2q7sSpVqqBFixYqR6Gnp6f1S0lEumIymfHWn/O7Hm1ZHS1rVtC6SEREurP6SAy2n7qmtv+e0r8xM8FYI5j9/vvv8fHHH6t8hLKPd7Vq1VQewxs3buD06dMqkH3yySfx2muvoVatWiX50URkIEsOXlI9sz7uLni9Z6jWxSEi0p3ElHRMWZnVKfBC53qoXdlH6yLpP5iVnld3d3cMGTIEP//8s9qXO6fU1FTs2rVLJd9u3bo1Pv/8c6Z9IXJAMkf2nbVZWy2OergBAvw4WlMYjnIRUWFkc4TYhFTUquSN5zrV07o4xghm33nnHfTo0aPQ78u+3ZK0W463334b0dHR1iojEenI7M1RuJqYitqVvDG0Q22ti2OXOMpFREU5diUBC3ZmxVGT+zeGpxu3/7ZKMFtUIJtXpUqV1EFEjiX6WhLm7Tirzif0CYOHKxvgvDjKRUR3W3MwYWkEMk1mteCrc0iA1kUyZjaDBQsWFHi77LU+bty4ey0TEenUtFXHslfdPtyIDXBho1y///47XnjhhXyBbM5Rrjlz5uD48eOoW7euJuUkIm38tP8i9p+7CW93F5WKi2wUzL744ouqp+DmzZvZt504cQJt27bFf//739L8SCLSuW0nr2LjsVi4OjthYt9GXHVrpVGuVq1a2bQ8RGQ/bialYcaaY+r85a4NUdXfS+siGTeYPXjwIC5evIgmTZpgw4YN+Oyzz9CyZUuEhobi8OHD1i8lEdm19EwTpq48qs4HtauN+gG+WhdJFzjKRUQ5vbv2OG4mpyMk0BdDuObAtsFsvXr18Ntvv+HRRx9Fz5498fLLL+Prr79Wixr8/f1L8yOJSMf+s/scTsXdRkUfd7z0cAOti6MbHOUiIguZWvDD3gvqfOrAcLi5cF+r4ip1Ta1atUotUJAUMuXLl8c333yDy5cvl/bHEZFO3UhKw6wNJ9X52O4N4e/tpnWRdIOjXEQkMjJNatGXkK2/29SpqHWRjB/MPvvss6o3QdLGSI7EP/74Q63OlQb5xx9/tH4pichuSSCbkJKB0CBf/P2+mloXR1c4ykVE4ttd51Q6Ln8vN4zrxY1myiSYlcZXVuOOHTtWLfIICgrC6tWrMWXKFDz99NOl+ZFEpEPHYxLw/e/n1Pmkfo3h4sxFXyXFUS4ixxabkIIP/xzdeq1nKCqV89C6SI4RzO7fvx/NmjXLd/uIESPU94jI+Mxms1r0ZTIDvZsEoV095pYuKY5yEZGkNJSdE5vXKI+/35c/XR9ZcdOEvHkQCxMSElKaH0lEOrPhaCx+i7oOd1dnjOvVSOvi6JJllMvSOWAZ5ZK5szLK9de//lXrIhKRDe04dQ0rDl+GDGpNGxgOZ45u2bZnVuZz7d69+673S0xMxLvvvqsaYyIyptSMTLy9OisX4vAH66BGRW+ti6RLHOUicux2dOKyiOyUhuHVOU/e5sGsDIU99thjCAsLU0NiixcvVr0K0uBu3LgRn3zyiepFqFq1Kg4cOIB+/frd9Wdu27ZN3U/2JZe5t0uXLi3y/lu2bFH3y3vExMQU9zKIyAoW/BaNc9eTEeDrgRc619e6OLrFUS4ix/XVtjM4cy0JVXw9MKZ7Q62L4xjTDJ555hk89dRTKohdtGgRvvzyS8THx6vvSUApQa7sbLN37140alS8IcekpCTVKyHDabKat7gkD6Ofn1/21wEB3DaTqKxcTUzFp5uj1PmrPUPh41Gq2UoOS0a53nrrLdx///13HeX6/PPPUa5cOdVTS0TGcf56cnY7OqFPI/h5MqXhvXAtaS+CBLRyCAlm79y5o7ZcdHMr+R+iV69e6igpCV5l1W9xpKamqsMiISFB/Z+enq4Oo7FckxGvTSus09xmrs1arNCkuh/6hQeUul6MXK9FXZNllEtSb8nIVOvWrdXolKenp9o84ejRo9ixY4eaO9unTx/MnDmzTMtORLZfPDtpeQRSM0xoX68S+jerpnWRdO+eulSkMdYiF2Lz5s1VgBoeHq56ODp06FDofWfMmIHJkyfnu339+vXw9jbuPD9JwE7WxToFLiYBi/9wkfEYPFzhBtauXXPPP9OI9ZqcnFymo1xEpB/rj8bi1xNX4ebipHb6ktc9lWEwK/NiCyIBbcOGDVWeRFuS+bhz5sxRPRkSzEpy8c6dO6vVwLJrTkFkf/MxY8bk6pmtUaMGunfvnmuqglFIj5AEB926dStVbznlxzr9X2/CU/P2wYyb6NMkCCP+2vSefp6R69UyAlRWo1xEpA/JaRmYvDxSnT/bsR7qVSmndZEcL5idNWtWgbffunVLNcbt27fH8uXLUbGibbZhkwURORdFyO87ffq0Ktd3331X6JtGQYss5A3DyG8aRr8+LTh6na45cgV7om/Cw9UZ4/uEWa0ujFivJb2eexnlkoW0MhVBFuNeuXIFS5YswcCBA4tcSNulS5d8t8tjJTUYEdnOJ5uicDk+BcEVvDCiCxfPahLMnj17ttDvnTlzRvUyTJgwQS1aKCtt2rRR88uIyHZS0jMxfU1WKq5nO9ZF9fJeWhdJ16w5ysWFtET6cCo2EV9vP6PO3+rXGF7uMmWLrMFqy5Dr1q2Ld955p8y3sz106JCafkBEtjP/t2hcuHEHgX4eeK5zPa2Lo3vWHOUqi4W0RHTv07QmLI1AhsmMbmGB6BoWqHWRDMWqOXVq1qxZopyvt2/fRlRUVmoKS8+vBKfSgMvPkvmuly5dwrfffqu+/9FHH6FOnTpo3LgxUlJS1JzZzZs3q8VcRGQbcYkpmL35VPa+4d7uTMV1r+xhlKskC2mZFYbulaPX6dJDl/H72RvwdHPGG70aWq0ejFyv6SW4Jqu+Kx05cgS1atUq9v337duXa+6WZaHW4MGDsWDBAjWH6/z589nfT0tLw9ixY1WAK5kImjZtqjZsKGj+FxFZxwfrTiIpLRPNgv0xsHl1rYtjeLYe5SrNQlpmhSFrccQ6Tc4A3j6UlQWma9V0HN75Kw5b+XdscLCsMPcUzBa2QleGxWTxgQSaEogWlzSg0vVeGAloc3r11VfVQURlI+JSPH7cf0GdT+wXxn3Dy0hJR7lsvZCWWWHoXjlynb614hhup19A3co+eHdoO7i7FnvzVYeu14S7ZIUpdTAr86sKy4cmtw8bNgyvv/56SX4kEdkp+aA5deVRyOfNfs2qoVUt22QpoXsf5bL1QlpmhSFrcbQ6PXzhFhbuzeoQePuRJvDxKnwL63vhZsB6Lcn1lCiY/fXXXwu8XT6ZN2jQQO1gExcXp3azISJ9WxcZo+Z4SSqu13uFal0cQ7H2KNe94kJaIuvLNGUt+pIOgUdaVEe7epW0LpJhlSiY7dSpU5HfP3z4sJpzlZmZea/lIiINpWZk4u3VTMVlK9Yc5eJCWiL7tPD3czhyKR6+nq4Y15sdArbEZclEVGQqrmc7MRWXtVlzlIsLaYnsz9XEVLy37oQ6f6VHCAJ8PbUukqExmCWifI3w7M1ZPX2v9giFjwebCWuz5igXF9IS2Z8Zq48hMSUDTar748m2ZTf/3VFZb0kdERnChxtO4HZqBpoG+6t5XkREVHy7z1zHLwcvQWYSTRsYDhdmgbG5EnW5/PHHH3fdHpGI9Cvycjx++HPl7cS+TMVFRFQSaRkmvLk0Qp0/2bYmmtXgLnt2F8zKjjGyOKGgIS3L7YUtaiAi/aTi6tu0KlrXZiouIqKSmPfbWZyKu41KPu54pTsXfdllMFvUFoxEpG/rj8Zi95kbKqE3U3HZFke5iIzn0q07+Hhj1tbf43s3gr+3sfK+GiaYLcsk3kRUtqm4pv+Zimv4g3UQXMG4W5TaA45yERnP5OWRuJOeiTa1K+LRllxvYLfB7HvvvYdRo0bByysr5+Rvv/2m9ve27AyTmJiI1157DZ9//rltSktENrHgt2icu56MKr4eeKFzfa2LY3gc5SIylk3HYtXolquzE6YODOeHUXsOZiX59pAhQ7KD2V69eqnk3HXr1lVfJycnY+7cuQxmiXSWiuvT7FRcIUzFVQY4ykVkHHfSMvHWikh1/swDdRAS5Kt1kRxOiVJz5R0SKyq3IRHpw4cbTqpUXJIP8bGWwVoXx+Fs374dTz31FNq1a6c2MhDfffcdduzYoXXRiKgYPt8SpTaZqebviRcfbqB1cRwS88wSObCjlxOwaG/W7lAT+zEVV1n7+eef0aNHDzXadfDgQaSmpqrb4+PjMX36dK2LR0R3cfrqbczdekadT+zXmCNbGmEwS+SgZGRlyspImMxAn6ZVcR9TcZW5adOmYc6cOfjqq6/g5va/lc8dOnTAgQMHNC0bEd29DZ24LAJpmSZ0CamCHo0DtS6SwyrxR4ivv/4a5cqVU+cZGRlqq8TKlStnLwAjIn1YF/m/VFzjmIpLE5KCq2PHjvlu9/f3x61btzQpExEVz4o/ruC3qOvwcHXG5P5c9KWbYLZmzZqqB8EiKChIze3Kex8i0k8qrn8+WJepuDQibWhUVBRq166d63aZL2tZWEtE9ichJV1tMiNGdqmPmpXYhuommI2OjrZdSYiozMz/LRrnbyQjwNcDz3eup3VxHNbw4cPx0ksvYd68eapX5/Lly9i1axfGjh2LiRMnal08IirErA0nVSaYOpV98M9O/OCpq2A2JSUFGzduRN++fbNTdVkWLKgf5uqKKVOmwNPT0/olJSKrkAZ4tiUVV89QLljQ0Ouvvw6TyYSHH35YpTaUKQeSt/uVV17BsGHDtC4eERUg8nI8/r0zq3NvyoDG8HB10bpIDq9EC8BkfqzkkbWYPXs2du7cqVbhyiFTDphjlsi+vb/uhErF1SzYH4+24C41WpLe2DfeeAM3btxAREQEdu/ejatXr6o5s3Xq1NG6eESUh8lkxoSlEWrhbN+mVfFggypaF4lKGsx+//33+Oc//5nrtoULF+LXX39Vx8yZM7F48WJrl5GIrCTiUjx+3H8hO40MU3FpQ0a0ZGRLdlCUzAWrV69GWFgYIiMjERISgo8//hgvv/yy1sUkojwW7buAg+dvoZyHK97sG6Z1cehPJRpflIUKTZo0yf5aphM4O/8vHm7Tpg1GjBhRkh9JRGWYRmbyikjIXicDmldDq1oVtC6Sw5L5sDLK1bVrVzW69fjjj2Po0KGqZ/aDDz5QX7u4cOiSyJ5cv52Kd9YcV+ejuzZAoB+nVOqyZ1ZSxeScIyvDYTlX4crcr5zfv5tt27ahX79+qFatmhpuW7p06V0fs2XLFrRs2VLNK6tfv76a+kBEd7fyjyvYG30TXm4ueJ2puDQlI1jffvstfvrpJ6xfvx6ZmZkq1eHhw4fx97//nYEskR16d+1xxN9JR2iQL4a0z52BhHQUzAYHB6t5XYX5448/1H2KKykpCc2aNcNnn31WrPufPXsWffr0QZcuXXDo0CGMHj1aLZJYt25dsX8nkaPuHT7jz1Rcz3Wqh6r+XloXyaFdvHgRrVq1Uufh4eHqw7lMK2CeSiL7tC/6Bn7cd1Gdv/1IOFxduOeUbqcZ9O7dWw2PSUCZN2PBnTt3MHnyZPW94urVq5c6ikt2ypFFETIMJxo1aqTyMc6aNUttCUlEBZu77TQux6egenkvPMs0MpqTnlh3d/dcmWAsm9EQkX3JyDSpRV/i7/fVQKta3C1R18Hs+PHj8eOPP6oFCiNHjkTDhg2zd7GRzAYyTCb3sRXJvyhzzHKSIFZ6aAsj0x5yTn1ISEhQ/6enp6vDaCzXZMRr04re6/TyrTuYs/W0On+tRwO4wIT0dJPWxdJ9vRblbtck85eHDBmiemQtaQ+fe+45+Pj45LrfL7/8YtNyEtHdLdgZjeMxiajg7abSGZLOg9nAwEC1WOH5559X+RGlQRYyNNatWzeVlkvuYysxMTH5fr58LQGq9Ax7eeUfOp0xY4bqMc5L5ql5ext3x44NGzZoXQTD0WudLjjpjJR0Z9TzNcN07gBWn4dd0Wu9FkVyxhZl8ODBub5+6qmnbFwiIiqNK/F31AYJQtYaVPT534gK2Y8SZ0uXYf61a9eqvIiS3UDIQqyKFe2z213S34wZMyb7awl8a9Soge7du8PPzw9G7BGS4EA+XLi5uWldHEPQc53uib6Bg7v2QaZifviPdgiraj/PeT3X691YRoAKM3/+/DIrCxGV3rSVx5CUlomWNcvj8VY1tC4OFaLUW/9I8CqpuMp6H/PY2Nhct8nXEpQW1CsrZBjPMpSXk7x5Gu0N1JGuTwt6q9NMkxnTVmf1KDzRpiaa1awEe6S3ei0Oo10PkSPadvIqVh25AknHPW1gE+bltmO6Wo7Xrl07bNq0Kddt0rMjtxNRbv/dcx7HriTAz9MV/+oeonVxyEaY4pDI+lLSMzFxWdair8HtayOsmv2MapGdBbO3b99WKbbksKTekvPz589nTxEYNGhQ9v1lgcSZM2fw6quv4vjx42qOrixI4045RLndSk7DB+tPqPMx3RpynpeBMcUhkfXN3XoG0deTEeDrodpQMug0A2vYt2+falAtLHNbZXGE9BRcuXIlO7C1zNddtWqVCl5lu0fJafv1118zLRdRHrJg4WZyOhoGlsNT99fSujhkQ0xxSGRd564n4bMtWWuCZMtaX09OG7J3mgaznTt3zs6IUJCChr7kMQcPHrRxyYj0S6YWfLf7nDp/q19jJvemXJji0LHTxmlFL3UqMcnEpRFIyzChfb2K6NGosl2XWS/1WholuSZNg1kisn5DPGlZJExmoE+Tqmhfv7LWRSI7wxSHjp02Tmv2XqeHrzth6ykXuDiZ0cU3DmvWrIEebLDzerVFisOcGMwSGcjyw5dVOi5PN2eM79NI6+KQQTDFITlCnSalZmDGJ7/JWITa9nvIw/Vh7/RQr7ZKcZgTg1kig1AN8erj6nxE5/pq61qivJjisPiMfn1asOc6/XxDFGISUlGjohdGPdwQbm4u0As3O67X0irJ9XAyHZFBfLL5FGISUlCzojeGd6yrdXHITjHFIVF+J2IS8c2Os+p8Sv9weOookCUGs0SGEBWXiG+2ZzXEb/UPY0PsQJjikOje1xpMWHpEbTTTo3EguoQGaF0kKiEGs0RGWPS1PBIZJjO6NgrAQ6G5F/eQsUmKwxYtWqhDyNxWOZ84caL6urAUh9IbK/lpJUUXUxySI/v5wCXsjb4Jb3cXTOrXWOviUClwziyRzq0+EoPfoq7D3dUZE/uyIXY0THFIdG8bzExffUydv/RwA1TjWgNdYs8skY7dTs3A1JVH1fnzneqhZiXjpkkiIrK299adwI2kNDQIKIenH6ijdXGolBjMEunYJ5v+t+jr+c71tC4OEZFuHDx/E//dkzUFZ9rAcLhxgxnd4l+OyACrbycPaMxFX0RExSSLvSYsjYDM0HmsZTDa1q2kdZHoHjCYJdL56tuejYPQJYSrb4mIius/u88h8nIC/DxdMa53qNbFoXvEYJZIh37afzF79e3EfmFaF4eISDfiElLw/roT6vzVnqGoXC7/hiCkLwxmiXRGFitw9S0RUem8vfoYElMz0CzYH0+0qal1ccgKGMwS6cyM1cdwMzkdoUG+XH1LRFQCO6OuYdmhy3BykkVfTeDi7KR1kcgKGMwS6cjvZ65j8f6LqiF++5EmXH1LRFRMaRkmTFgWoc7/cX8tNAn217pIZCV8JyTSidSMTLyxNKshlqGxVrUqaF0kIiLd+Gr7GZy5mqTmyI7tHqJ1cciKGMwS6cScLWcQFXcblcu547UeXH1LRFRcF24k49PNp9T5hD6N4O/lpnWRyIoYzBLpQFRcIj77NUqdy97h/t5siImIimvyikikpJtwf92KGNC8mtbFIStjMEtk50wmM8b/EoG0TBMeCg1A36ZVtS4SEZFubDgai43H4uDq7KR2+nKSRQdkKAxmiezcD3svYE/0DZVTdsqAxmyIiYiKKTktA28tj1TnwzvWRf0AX62LRDbAYJbIjl2Jv5OdU1YWLARX8Na6SEREujF7cxQu3bqD6uW98OJDDbQuDtkIg1kiO96y9o0lEbidmoEWNctjSPvaWheJiEhXaw0kg4GY1C8MXu4uWheJjBzMfvbZZ6hduzY8PT3Rtm1b7Nmzp9D7LliwQA2z5jzkcURGs/zwZWw+Hgd3F2e891hTJvcmIipBZ8CbSyORnmnGw6EB6N44SOsikZGD2UWLFmHMmDGYNGkSDhw4gGbNmqFHjx6Ii4sr9DF+fn64cuVK9nHu3LkyLTORrV1NTM2e5zXqofpoEMh5XkREJekM2HXmOjzdnPFW/8ZaF4eMHsx++OGHGD58OIYOHYqwsDDMmTMH3t7emDdvXqGPkd7YoKCg7CMwMLBMy0xk6x6FCUuPqC1rG1X1w3Od62ldJCIi3Yi/k46pK7PWGox6qAFqVORaA6Nz1fKXp6WlYf/+/Rg3blz2bc7OzujatSt27dpV6ONu376NWrVqwWQyoWXLlpg+fToaNy74k1dqaqo6LBISEtT/6enp6jAayzUZ8docpU5X/HEF6yJjVRqZdx4JA0yZSDdlwmiM/Fw14jUR6cWH60/g2u1U1K3ig2EP1tG6OGT0YPbatWvIzMzM17MqXx8/frzAx4SEhKhe26ZNmyI+Ph7vv/8+2rdvj8jISAQHB+e7/4wZMzB58uR8t69fv171ABvVhg0btC6C4ZRFnSakATMOyyIFJ3SrloHogzsQfRCGZsTnanJystZFIHJIRy7G47vdWVMPpw4Ih4crF305Ak2D2dJo166dOiwkkG3UqBHmzp2LqVOn5ru/9PrKnNycPbM1atRA9+7d1dxbI/YISXDQrVs3uLlxlyg91alML3h+4SEkZ1xFWFVffDCsLdxcNJ8JZDNGfq5aRoCIqOxkmrKmaJnMQP9m1dChfmWti0SOEMxWrlwZLi4uiI2NzXW7fC1zYYtD3gRbtGiBqKisrT7z8vDwUEdBjzPaG6gjXZ8R63TR3vPYdPyqyl7w4d+aw9sz//PWiIz4XDXa9RDpwQ97z+PwxXiU83DFhD6NtC4OlSFNu33c3d3RqlUrbNq0Kfs2mQcrX+fsfS2KTFM4cuQIqlblFp+kX+evJ2PKiqPq/F89GiI0yHijBkREtiJzZN9be0Kdj+3eEAF+TNnpSDSfZiBTAAYPHozWrVujTZs2+Oijj5CUlKSyG4hBgwahevXqau6rmDJlCu6//37Ur18ft27dwsyZM1VqrmHDhml8JUSlHxobu/gQktIy0aZORTzzQF2ti0REpCszVh9XWQwaV/PDP+6vpXVxqIxpPiHvb3/7m1rENXHiRDRv3hyHDh3C2rVrsxeFnT9/XuWStbh586ZK5SXzZHv37q3mpu3cuVOl9SLSoy+2RGFv9E01NPbB4824OQKVCjefIUf1+5nr+PnARTg5AdMGhsPVwGsNyE57ZsXIkSPVUZAtW7bk+nrWrFnqIDKCA+dvYtbGU+p8cv/GzIdI97T5jOTplkBWRrhk85kTJ04gICCgwMfIAlj5voUEtER6k55pwpvLItT53++riRY1K2hdJNIAP74QaSQhJR0v/XBQTTMY0LwaHm1ZXesikU5x8xlyVPN/O4uTsbdR0ccdr/YI0bo45Mg9s0SOuW94BC7cuIPgCl6YOjCcPWNUKtx8xvqMvKGHker0SnwKPvpzZOtf3RqgnLuTw/3NjPxcTS/BNTGYJdLAor0XsOzQZTU/9uO/N4efJ1M5Uelw8xnbMeKGHkaq03knnJGc5ow6vmZ4xRzG6tWH4ag2OPjmMwxmicrYsSsJmLQ8Up3/q3sIWtWqqHWRyMFw8xnH3dDDKHW69eRVHN51UHUIfDqoHUKCfOGIjPxcTSjB5jMMZonK0O3UDIz4/gBSM0zoHFIFz3ZkGi66N9x8xnaMfn16rdOU9ExMXZ21ePHpDrURXoMdAm4GfK6W5Hq4AIyoDOfJvvbTHzhzLQlV/T3x4V+bw5lpuOgecfMZcjRfbDmNc9eTEeTniZe6NtS6OGQH2DNLVEa+3n4Wq45cgZuLE2b/Xwu1+pbIGrj5DDmKs9eSVDArJvYLU/m5ifgsICoDO09fw4w1x9T5m33DOE+WrL75zNWrV9XmMzExMWoDmrybz0iGg7ybz8h9K1SooHp2ufkM6WF0a+KyCKRlmtCxYRX0Ci/eNBoyPgazRDZ28WYyRi08CJMZeLRFdW61SDbBzWfI6FYficH2U9fg7uqMKf0bM50hZeOcWSIbSkrNwLB/78P1pDSEVfXD2480YQNMRFSKxbNTVmZlgXmhcz3UruyjdZHIjjCYJbIRk8mMlxcdwvGYRFQu54GvBreGl7uL1sUiItKdjzacRGxCKmpV8sZzneppXRyyMwxmiWxk5voTWH80Fu4uzpj7j1aoXt5L6yIREekyN/f8ndHqfMqAcHi6sVOAcmMwS2QD3/9+LnvF7TuPNUGrWhW0LhIRkS5HuCYsjUCmyYw+TaqiU8MqWheJ7BCDWSIr23QsFm8ujVDno7s2wKMt828PSkREd/fT/ovYf+4mfNxdVCYYooIwmCWyogPnb2Lkn5kLHm8VjJcebqB1kYiIdOlmUlp2SsOXuzVEkL+n1kUiO8VglshKjsckYMi8PbiTnokHG1TG9EeZuYCIqLTeW3ccN5PTERrki8Hta2tdHLJjDGaJrCD6WhL+8c0eJKRkoGXN8mrBl5sLX15ERKUd5frvngvqfOrAcLanVCQ+O4ju0YUbyXjy699xNTFV9SDMH9IG3u7cj4SIqDQyMk2YsCRr3YFM17qvNndMpKIxmCW6x0D271/uxqVbd1C3sg++faYN/L3dtC4WEZFufbvrHI5eSUB5bzeM691I6+KQDjCYJSql89dzB7L//ef9CPDlAgUiotKKTUjBhxtOqvPXeoaioo+71kUiHeBYKFEpk3gPmrdHTS2wBLKBfgxkiYjuxbRVx9TWtc1rlMffWtfQujikEwxmiUpo/7kbGDp/r1rsJXNkZWoBe2SJiO7NjlPXsOLwZTg7AdMGhsNZToj0Ms3gs88+Q+3ateHp6Ym2bdtiz549Rd5/8eLFCA0NVfdv0qQJVq9eXWZlJce26o8r+L+vfleBbOtaFbDon+0YyBIR3aPUjExMXJa16GtQu9oIr+6vdZFIRzQPZhctWoQxY8Zg0qRJOHDgAJo1a4YePXogLi6uwPvv3LkTTzzxBJ555hkcPHgQAwcOVEdERNaLgMgWzGZgztYzGLHwAFIzTHgoNADfPdOWi72IiKzgy61ncOZaEqr4emBM94ZaF4d0RvNg9sMPP8Tw4cMxdOhQhIWFYc6cOfD29sa8efMKvP/HH3+Mnj174pVXXkGjRo0wdepUtGzZErNnzy7zspNjSE7LwHdRzvhgY5T6emiH2vhqUGt4ubtoXTQiIkMspp39a1b7OqFPI/h5spOAdDRnNi0tDfv378e4ceOyb3N2dkbXrl2xa9euAh8jt0tPbk7Sk7t06dIC75+amqoOi4SEBPV/enq6Ooqj7+ydqjfO1dkJri7OcHdxUgmc3f78393VGR5yuLmo/z3lcHNRh5ebswp6JO+o7C3t4+ECH3dXlPNwha+nK/w8XdXjrMVyTcW9Nira2WtJeGHhIURdc4aLkxPe7BOCJ9vWhCkzA6ZMrUunb0Z+rhrxmohswWw2Y9LyCPUe275eJfRvVk3rIpEOaRrMXrt2DZmZmQgMDMx1u3x9/PjxAh8TExNT4P3l9oLMmDEDkydPznf7+vXrVQ9wcZyJc0G62XYT0V2czPB2RfZRztUMHzf5HyjnZoavG+DnDvi5mdX/Xi7A3XZJ3bBhg83K6yjTCvZedcJPZ52RanJSdT+kYQYqXI/A6tWc0mJNRnyuJicna10EIl1YfzQWv564qjqHpgwI5xbgVCqGz2Ygvb45e3KlZ7ZGjRro3r07/Pz8ivUzqjeNR3qmCRmZZvV/usmsdihJyzAhTf1vVv/LBPaUdBNS0024k56pvk5Oy8SdtEwkp2edJ6VmICk1E4mpGSr9iARNmWYnJKZDHVmKfjF7ujkjwNcDVf09Uc3fE1X9vRBcwRPVy3shyNcNkXt3oGf3bnBz41BNadxMTsPE5cew9nSs+rp1TX/0r3Idf+nDOrV276UEst26Ga9eLSNARFQ4eT+cvDxSnQ9/sC7qB5TTukikU5oGs5UrV4aLiwtiY7OCBgv5OigoqMDHyO0lub+Hh4c68pI3z+K+gbauUxm2YDKZkZSWgfg76dnHreR0FUzduJ2G60lZx7XEVFy7nYq4xFR1HwmYz9+4o46COMMFs07sRp0q5VC7krfKg1ovoBzqVSmnAmB+8i18uGvpoUuYtvKYqneZVvJyt4Z4pn1NrFu7pkTPGSo+I9ar0a6HyBY+2XwKl+NTVEfMqIcaaF0c0jFNg1l3d3e0atUKmzZtUhkJhMlkUl+PHDmywMe0a9dOfX/06NHZt0nvjtyuN5JDz9fTTR3BFYr3mJT0TMQlpOJK/B1ciU/B5fg7uHzrDi7evKO2Vr1w847qMZb/5diW5/Eyb1c+/TYI9EVIoC8aBvmiUZCvWkHqyEHuydhETFlxFDuirqmvGwaWwwePN0eTYH/OfyQiskGb+832s+p8cv/GXFBL+p5mIFMABg8ejNatW6NNmzb46KOPkJSUpLIbiEGDBqF69epq7qt46aWX0KlTJ3zwwQfo06cPfvjhB+zbtw9ffvklHIEsKqtZyVsdBUlNTcMPy9agXvP7cfFWKs5eT8LZq0k4ffU2zl1PRlJaJg5fjFdHTpV83BFa1RdhVf0QVs0Pjav5qx5dWfBmZHEJKZi18SQW7b0AkxlqAd+LDzdQQ16ysI+IiKw/CjZhaQQyTGZ0CwtE17Dc62CIdBfM/u1vf8PVq1cxceJEtYirefPmWLt2bfYir/Pnz6sMBxbt27fHwoULMWHCBIwfPx4NGjRQmQzCw8M1vAr76u0t7wG0rVMRD+QZ6pT5vhLQnopNxMnY2+qT8bGYBERfS1LD6r9FXVeHhQR2jar6Iby6H5pU91dJrBsG+qoMDnp36dYdzN16Gj/svaB6skWv8CC83isUtSr5aF08IiLDWnLwEvacvaHWf0zqF6Z1ccgANA9mhUwpKGxawZYtW/Ld9vjjj6uDSkaCUJliIEevJrmnLqjA9koCjl5OQOTlBHUuvbiHLtxSh4X0Vsq0BAlscwa4eujFlN6A38/ewH92n8PaiBjVKyBa1aqAcb1C0bp2Ra2LSERkaLLuY/rqY+pcRsGCKxQvqxCR3QezpP3UhabB5dWRc3GaTFGQwDbiUjyOXIxHxOV4JKZk5Jum4O7irKYoyNSExmqKgh9Cg/zsZg7Umau3seLwFSw/fAmnryZl3y45DUc+VB/t6lZy6PnCZAyyLfjMmTPVCJfspPjpp5+qqVtFbQv+5ptvIjo6Wo1wvfvuu+jdu3eZlpkcz6yNUbh2O011qgx7oK7WxSGDYDBLhU5XkOwHcliSWEuAe/5GMo5cis8KcP/8PyElA39cjFdH9uOdgNqVfdAoyE/13IYEZfUI16zoY/NeXPnkf/D8TWw/dQ1bT15FVNzt7O95ublgYIvqeOr+mir4JjICy7bgsoNi27Zt1doD2UzmxIkTCAgIKHRbcFmL0LdvXzV1SxbhypbinLJFtvLHDScsPHlBnU8dEK6LET3SBwazVKIAVwJUOfr9GeDK0L0lwJVeXDmOXo5Xn7zPXE1Sx6ojV7J/houzE2pU8FLzUmtV8lYpWapJflx/T1Qu54HK5dzV7mh36ymVwPpGchpi4lNUJgdZ4CZzgeX3n8oRvFp+5wP1K6sy92gcqLJHEBlJzm3BhQS1q1atUtuCv/7660VuCy5kW3DJCiPbgstjiaxJ3ie+2HoG8044QyZ3/aVVMNrVq6R1schAGMzSPZGgMysw9UHfpv/bhjAuMQXHriTiZEwiTqgFZ4k4HXdbzcONvp6sjsJI8CkBrRzyyV3yvUoDmGkyq8VaiSnpatMJ2XCiMBIot6ldEZ1DAlQg6+/NAJaMSS/bgv/rpyM4HpMIvQRfibdd8Nnp3zgFyQokN/q5G9LmO+H/7quOCX1CmfLQSrgteBYGs2QTAb6e6ujUsEquN4iYhBScvZaE89eTVeMmOXLliE3I2hhCdkmToNWyiURR5D2mSrmsndDqVsmaxiC5c5vXLK96eYkcgV62BT982gXRt/UUGDrhSvL/5tjTvXF2MuPxOia0dT2HDevOaV0cw9ng4NuCM5ilMiM9HLL1rhzt6xV8n+S0DCTcka1+03E7NTN722DZ4VeyMUgvrZ+XG/w83VDe280QacKIHGFb8OCm8WpERQ8yMjJwYP8BtGzVEq6ufJu0hmB/d0Tu2W7I7au1xG3Bs/BVSnbF291VHYCn1kUh0gW9bAveykbbgtsqQEg6bUankEDDBQha1mmkQbevtgduBqzXklwPu7WIiHQs57bgFpZtwQvb5tuyLXhOet0WnIiIPbNERDrHbcGJyJExmCUi0jluC05EjozBLBGRAXBbcCJyVJwzS0RERES6xWCWiIiIiHSLwSwRERER6ZbDzZmVXahKmoxXb7n8ZNcMuT6j5ZzTCuvUNoxcr5b2xdLeGA3bUSop1qltGLleE0rQjjpcMJuYmLU3uOxeQ0Rk6/bG398fRsN2lIjsqR11Mhu166AQkkz88uXL8PX1VdurGo1lm8kLFy4Ue5tJKhrr1DaMXK/SrEoDXK1atVwpsYyC7SiVFOvUNoxcr+YStKMO1zMrFRIcHAyjkye10Z7YWmOd2oZR69WIPbIWbEeptFintuHn4O2o8boMiIiIiMhhMJglIiIiIt1iMGswHh4emDRpkvqfrIN1ahusV7JXfG5aH+vUNlivDroAjIiIiIiMgz2zRERERKRbDGaJiIiISLcYzBIRERGRbjGYJSIiIiLdYjBrUNHR0XjmmWdQp04deHl5oV69emrFY1pamtZF053PPvsMtWvXhqenJ9q2bYs9e/ZoXSTdmjFjBu677z61c1RAQAAGDhyIEydOaF0sogKxHbUetqPWw3Y0PwazBnX8+HG15eTcuXMRGRmJWbNmYc6cORg/frzWRdOVRYsWYcyYMeoN7MCBA2jWrBl69OiBuLg4rYumS1u3bsWIESOwe/dubNiwAenp6ejevTuSkpK0LhpRPmxHrYPtqHWxHc2PqbkcyMyZM/HFF1/gzJkzWhdFN6QHQT4Bz549W30tb2yyD/aoUaPw+uuva1083bt69arqWZDGuWPHjloXh+iu2I6WHNtR27rKdpQ9s44kPj4eFStW1LoYuiFDifv370fXrl1z7UkvX+/atUvTshnpOSn4vCS9YDtaMmxHbS+e7SiDWUcRFRWFTz/9FM8++6zWRdGNa9euITMzE4GBgblul69jYmI0K5dRSO/M6NGj0aFDB4SHh2tdHKK7YjtacmxHbYvtaBYGszojQzJOTk5FHjLPK6dLly6hZ8+eePzxxzF8+HDNyk6Uk8z5ioiIwA8//KB1UcjBsB0lo2A7msX1z/9JJ8aOHYshQ4YUeZ+6detmn1++fBldunRB+/bt8eWXX5ZBCY2jcuXKcHFxQWxsbK7b5eugoCDNymUEI0eOxMqVK7Ft2zYEBwdrXRxyMGxHyw7bUdthO/o/DGZ1pkqVKuooDulJkAa4VatWmD9/vpqnRMXn7u6u6m7Tpk0q9YllSEe+lkaESk7Wm8qijyVLlmDLli0q5RFRWWM7WnbYjlof29H8GMwalDTAnTt3Rq1atfD++++r1Y4W/DRcfJJOZvDgwWjdujXatGmDjz76SKU/GTp0qNZF0+2Q2MKFC7Fs2TKVI9EyZ87f31/l8SSyJ2xHrYPtqHWxHc2PqbkMasGCBYU2FPyTl4ykk5F0PNJgNG/eHJ988olKNUMlJ3MRCyI9Xncb9iUqa2xHrYftqPWwHc2PwSwRERER6RYn/xARERGRbjGYJSIiIiLdYjBLRERERLrFYJaIiIiIdIvBLBERERHpFoNZIiIiItItBrNEREREpFsMZomIiIhItxjMEhEREZFuMZglIiIiIt1iMEtEREREusVglqgAV69eRVBQEKZPn559286dO+Hu7o5NmzZpWjYiIr1gW0plwclsNpvL5DcR6czq1asxcOBA1fCGhISgefPmGDBgAD788EOti0ZEpBtsS8nWGMwSFWHEiBHYuHEjWrdujSNHjmDv3r3w8PDQulhERLrCtpRsicEsURHu3LmD8PBwXLhwAfv370eTJk20LhIRke6wLSVb4pxZoiKcPn0aly9fhslkQnR0tNbFISLSJbalZEvsmSUqRFpaGtq0aaPmd8k8r48++kgNjwUEBGhdNCIi3WBbSrbGYJaoEK+88gp++uknHD58GOXKlUOnTp3g7++PlStXal00IiLdYFtKtsZpBkQF2LJli+o9+O677+Dn5wdnZ2d1vn37dnzxxRdaF4+ISBfYllJZYM8sEREREekWe2aJiIiISLcYzBIRERGRbjGYJSIiIiLdYjBLRERERLrFYJaIiIiIdIvBLBERERHpFoNZIiIiItItBrNEREREpFsMZomIiIhItxjMEhEREZFuMZglIiIiIujV/wPEF+PdYUXAhQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# sample data\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu = gelu(x)\n",
    "y_relu = relu(x)\n",
    "\n",
    "# plot the results\n",
    "plt.figure(figsize=(8, 3))\n",
    "\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "  plt.subplot(1, 2, i)\n",
    "  plt.plot(x, y)\n",
    "  plt.title(f\"{label} activation function\")\n",
    "  plt.xlabel(\"x\")\n",
    "  plt.ylabel(f\"{label}(x)\")\n",
    "  plt.grid(True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10a39a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "  def __init__(self, cfg):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(cfg[\"embed_dim\"], 4 * cfg[\"embed_dim\"]), # 4 is what gpt2 uses\n",
    "      GELU(),\n",
    "      nn.Linear(4 * cfg[\"embed_dim\"], cfg[\"embed_dim\"])\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.layers(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d7d5bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73d22e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 768)\n",
    "ffn(x).shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cbf5f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[     0.0148,     -0.0353,     -0.0022,  ...,      0.0333,\n",
       "             -0.0356,      0.0199],\n",
       "        [    -0.0170,     -0.0258,      0.0280,  ...,      0.0240,\n",
       "              0.0314,      0.0344],\n",
       "        [     0.0082,      0.0230,      0.0001,  ...,     -0.0335,\n",
       "              0.0171,     -0.0037],\n",
       "        ...,\n",
       "        [     0.0281,      0.0268,     -0.0041,  ...,     -0.0031,\n",
       "             -0.0273,     -0.0046],\n",
       "        [    -0.0025,     -0.0127,     -0.0169,  ...,     -0.0045,\n",
       "             -0.0046,     -0.0345],\n",
       "        [     0.0264,     -0.0037,      0.0053,  ...,     -0.0051,\n",
       "             -0.0041,      0.0070]], requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn.layers[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fcad3c",
   "metadata": {},
   "source": [
    "## Adding shortcut connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2eefd809",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "  def __init__(self, layer_sizes, use_shortcut):\n",
    "    super().__init__()\n",
    "    self.use_shortcut = use_shortcut\n",
    "    self.layers = nn.ModuleList([\n",
    "      nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "      nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "      nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "      nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "      nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU()),\n",
    "    ])\n",
    "    \n",
    "  def forward(self, x):\n",
    "    for layer in self.layers:\n",
    "     # computer the output of the current layer\n",
    "     layer_output = layer(x)\n",
    "     # check if shortcut can be applied\n",
    "     if self.use_shortcut and x.shape == layer_output.shape:\n",
    "      x = x + layer_output\n",
    "     else:\n",
    "      x = layer_output\n",
    "    return x\n",
    "\n",
    "def print_gradients(model, x):\n",
    "  # forward pass\n",
    "  output = model(x)\n",
    "  target = torch.tensor([[0.]]) # placeholder target for the loss function as we are not training\n",
    "\n",
    "  # compute loss\n",
    "  loss = nn.MSELoss() # just for simplicity, we use a simple loss function\n",
    "  loss = loss(output, target)\n",
    "\n",
    "  # backward pass to calculate gradients\n",
    "  loss.backward()\n",
    "\n",
    "  # print the gradients\n",
    "  for name, param in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "      # print the mean absolute gradients of the weights\n",
    "      print(f\"{name} has a gradient mean of {param.grad.abs().mean().item()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8396351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has a gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has a gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has a gradient mean of 0.0007152041071094573\n",
      "layers.3.0.weight has a gradient mean of 0.0013988735154271126\n",
      "layers.4.0.weight has a gradient mean of 0.005049645435065031\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "use_shortcut = False\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "model = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut)\n",
    "\n",
    "print_gradients(model, sample_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09c924b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has a gradient mean of 0.22169791162014008\n",
      "layers.1.0.weight has a gradient mean of 0.20694106817245483\n",
      "layers.2.0.weight has a gradient mean of 0.32896995544433594\n",
      "layers.3.0.weight has a gradient mean of 0.2665732204914093\n",
      "layers.4.0.weight has a gradient mean of 1.3258540630340576\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "use_shortcut = True\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "model = ExampleDeepNeuralNetwork(layer_sizes, use_shortcut)\n",
    "\n",
    "print_gradients(model, sample_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb50ced",
   "metadata": {},
   "source": [
    "## Connecting attention and linear layers in a transformer block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcb52792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import code from chapter-3.ipynb and chapter-2.ipynb that we need here\n",
    "import sys\n",
    "# Add the directory containing this notebook to Python path\n",
    "notebook_dir = '/Users/wolf/ai/LLMs-from-scratch/build_an_llm_from_scratch'\n",
    "if notebook_dir not in sys.path:\n",
    "    sys.path.insert(0, notebook_dir)\n",
    "    \n",
    "from previous_chapters_before_four import MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9592093",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "  def __init__(self, cfg):\n",
    "    super().__init__()\n",
    "    self.attn = MultiHeadAttention(\n",
    "      d_in = cfg[\"embed_dim\"],\n",
    "      d_out = cfg[\"embed_dim\"],\n",
    "      context_length = cfg[\"context_length\"],\n",
    "      num_heads = cfg[\"n_heads\"],\n",
    "      dropout = cfg[\"drop_rate\"],\n",
    "      qkv_bias = cfg[\"qkv_bias\"]\n",
    "    )\n",
    "\n",
    "    self.ff = FeedForward(cfg)\n",
    "    self.norm1 = LayerNorm(cfg[\"embed_dim\"])\n",
    "    self.norm2 = LayerNorm(cfg[\"embed_dim\"])\n",
    "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "  def forward(self, x):\n",
    "    shortcut = x\n",
    "    x = self.norm1(x)\n",
    "    x = self.ff(x)\n",
    "    x = self.drop_shortcut(x)\n",
    "    x = x + shortcut\n",
    "\n",
    "    shortcut = x # keep the x from the previous layer for the shortcut connection\n",
    "    x = self.norm2(x)\n",
    "    x = self.attn(x)\n",
    "    x = self.drop_shortcut(x)\n",
    "    x = x + shortcut # add the shortcut connection\n",
    "\n",
    "    return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0fa96aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[     0.1416,      0.2467,      0.2317,  ...,      0.1780,\n",
       "               0.1966,      1.3443],\n",
       "         [     0.0929,      0.3889,      0.6629,  ...,      1.1015,\n",
       "               0.3640,      0.4361],\n",
       "         [     0.2067,      0.5458,      0.1572,  ...,     -0.2758,\n",
       "               0.6164,      0.4802],\n",
       "         [     0.4659,      0.4988,      0.8070,  ...,     -0.1181,\n",
       "               0.2424,      1.3027]],\n",
       "\n",
       "        [[     0.9658,      1.2531,      1.2318,  ...,      0.5799,\n",
       "               0.0377,      0.4316],\n",
       "         [     0.5739,     -0.0013,      0.6739,  ...,      0.3818,\n",
       "               0.5303,      0.2684],\n",
       "         [     0.9065,      0.4001,      0.2467,  ...,      0.1645,\n",
       "               0.8935,      1.2748],\n",
       "         [     0.9911,      0.7147,      0.3522,  ...,      0.6840,\n",
       "               0.2418,      0.5326]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = TransformerBlock(GPT_CONFIG_124M)\n",
    "\n",
    "x = torch.rand(2, 4, 768)\n",
    "\n",
    "output = model(x)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a84fb728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 768])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d2b98c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 768])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eac2ac9",
   "metadata": {},
   "source": [
    "## Coding the GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb75ec3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "# copied from above\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fc75eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed361f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the DummyGPTModel class from above\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "  def __init__(self, cfg):\n",
    "    super().__init__()\n",
    "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"embed_dim\"])\n",
    "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"embed_dim\"])\n",
    "    self.dropout = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    # Placeholder for the transformer blocks\n",
    "    self.trf_blocks = nn.Sequential(\n",
    "      *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
    "    )\n",
    "\n",
    "    # Placeholder for layer norm\n",
    "    self.final_norm = LayerNorm(cfg[\"embed_dim\"])\n",
    "    self.out_head = nn.Linear(\n",
    "      cfg[\"embed_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "    )\n",
    "\n",
    "  def forward(self, in_idx):\n",
    "    batch_size, seq_len = in_idx.shape\n",
    "    tok_embeds = self.tok_emb(in_idx)\n",
    "    pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "    x = tok_embeds + pos_embeds\n",
    "    x = self.dropout(x)\n",
    "    x = self.trf_blocks(x)\n",
    "    x = self.final_norm(x)\n",
    "    logits = self.out_head(x)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55602469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7053,  0.3617,  0.0581,  ...,  0.5794,  0.4369, -0.5395],\n",
       "         [ 0.3149, -0.4990, -0.7606,  ...,  0.0588,  0.2850, -0.2483],\n",
       "         [ 1.0219,  0.0603,  0.0629,  ..., -0.0370, -0.3881, -0.1416],\n",
       "         [-0.5710,  0.1734, -0.4368,  ...,  0.8466,  0.2312, -0.2404]],\n",
       "\n",
       "        [[-0.3798,  0.2834, -0.1104,  ...,  0.1926,  0.3591, -0.8746],\n",
       "         [ 0.1633,  0.2323,  0.2081,  ...,  0.9451, -0.2375,  0.3755],\n",
       "         [ 1.0812,  0.8785, -0.1139,  ...,  0.8412,  0.3455, -0.1142],\n",
       "         [ 0.1560,  0.1270,  0.4120,  ...,  1.2442, -0.5060,  0.2523]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "\n",
    "output = model(batch)\n",
    "output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d05200dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 50257])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5cf1e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05d98103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163009536"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "total_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0c92f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6241da7",
   "metadata": {},
   "source": [
    "We have more than 124 million parameters because we do not do weight sharing for input and output embedding. \n",
    "\n",
    "In the original GPT-2, the input embedding matrix (tok_emb) and the output projection matrix (out_head) share the same weights. This reduces parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71a226c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters of the original GPT-2 model: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total parameters of the original GPT-2 model: {total_params - model.out_head.weight.numel():,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0a5189",
   "metadata": {},
   "source": [
    "### Current implementation (no weight sharing)\n",
    "Looking at the GPTModel class:\n",
    "\n",
    "- `self.tok_emb = nn.Embedding(vocab_size, embed_dim)` — creates a matrix of size (50257, 768)\n",
    "- `self.out_head = nn.Linear(embed_dim, vocab_size, bias=False)` — creates a matrix of size (768, 50257)\n",
    "\n",
    "These are separate, so you have:\n",
    "\n",
    "- Embedding parameters: 50257 × 768 = 38,597,376\n",
    "- Output head parameters: 768 × 50257 = 38,597,376\n",
    "- Total for these two: 77,194,752 parameters\n",
    "\n",
    "### Original GPT-2 (with weight sharing)\n",
    "If the weights are shared (typically by tying `out_head.weight = tok_emb.weight.T`), you only store one set:\n",
    "- Shared parameters: 50257 × 768 = 38,597,376 parameters\n",
    "This saves about 38.6 million parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb71c5c",
   "metadata": {},
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "897fb9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
    "  for _ in range(max_new_tokens):\n",
    "    idx_cond = idx[:, -context_size:] # truncating to the size the model supports (if it was longer)\n",
    "\n",
    "    with torch.no_grad(): # we are not training, so we do not need to compute gradients\n",
    "      logits = model(idx_cond)\n",
    "    logits = logits[:, -1, :] # only the last row of the logits (the new token)\n",
    "\n",
    "    probas = torch.softmax(logits, dim=-1) # computing the probabilities\n",
    "    idx_next = torch.argmax(probas, dim=-1, keepdim=True) # argmax looks up the index position (finding the index position with the highest probability)\n",
    "\n",
    "    idx = torch.cat((idx, idx_next), dim=1) # concatenating the new token to the context\n",
    "\n",
    "  return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f028b3b",
   "metadata": {},
   "source": [
    "idx (index) corresponds to token id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b676fa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hello, I am\"\n",
    "\n",
    "encoded = tokenizer.encode(start_context)\n",
    "print(\"encoded:\", encoded)\n",
    "\n",
    "# model expects a batch dimension even if we only have one example\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da6c77ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,    11,   314,   716]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a23a7a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15496,    11,   314,   716, 27018,  7283, 46275,  7005, 12079, 20656]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = generate_text_simple(\n",
    "  model=model, \n",
    "  idx= encoded_tensor, \n",
    "  max_new_tokens=6, \n",
    "  context_size=GPT_CONFIG_124M[\"context_length\"] \n",
    ")\n",
    "out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa23e660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, I am Feature IT snowball Educowski Ambassador'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(out[0].tolist()) # we have to convert the tensor to a list first because the tokenizer expects a list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bf2d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (build-a-llm-from-scratch)",
   "language": "python",
   "name": "build-a-llm-from-scratch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
